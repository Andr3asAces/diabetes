{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project for the IBM course Deep learning and Reinforcement learning:\n",
    "\n",
    "- Trained a neural network  using Tensorflow to predict diabetes on the Pima Diabetes Dataset.  \n",
    "\n",
    "- Trained a baseline Random forest and compared the performance with the neural network model.\n",
    "\n",
    "- Experimented with different neural network architectures (feel free to try yourself) and \n",
    "\n",
    "- The most improtant findings are highlighted at the end of the notebook! Dont' miss em!\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0               6                     148              72              35   \n",
       "1               1                      85              66              29   \n",
       "2               8                     183              64               0   \n",
       "3               1                      89              66              23   \n",
       "4               0                     137              40              35   \n",
       "\n",
       "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0        0  33.6              0.627   50             1  \n",
       "1        0  26.6              0.351   31             0  \n",
       "2        0  23.3              0.672   32             1  \n",
       "3       94  28.1              0.167   21             0  \n",
       "4      168  43.1              2.288   33             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load diabetes dataset\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('./data/diabetes.csv', names=names, header=0)\n",
    "diabetes_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13</td>\n",
       "      <td>126</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.583</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>245</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.851</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>66</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.306</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.244</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "72               13                     126              90               0   \n",
       "31                3                     158              76              36   \n",
       "368               3                      81              86              16   \n",
       "60                2                      84               0               0   \n",
       "184               4                     141              74               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "72         0  43.4              0.583   42             1  \n",
       "31       245  31.6              0.851   28             1  \n",
       "368       66  27.5              0.306   22             0  \n",
       "60         0   0.0              0.304   21             0  \n",
       "184        0  27.6              0.244   40             0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure they are np arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: has_diabetes, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalanced classes\n",
    "diabetes_df['has_diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train a baseline Random Forest model with 200 trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.792\n",
      "roc-auc is 0.856\n"
     ]
    }
   ],
   "source": [
    "# soft prediction - probabilities of having diabetes by majority vote (percent of trees voting yes)\n",
    "y_preds  = rf_model.predict_proba(X_test)\n",
    "\n",
    "# hard prediction - probabilities of having diabetes\n",
    "y_preds_binary = rf_model.predict(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_preds_binary)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_preds[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred) # False Postive Rate, True Positive Rate, Th\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5) \n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 15],\n",
       "       [17, 30]], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_preds_binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest does much better than a random guess with 85% roc-auc and accuracy close to 80%. However a model by just predicting that someone does not have diabetes will get 65% accuracy!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural network\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further splitting of the training set into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we neural networks are all about dot products it is best practice to scale the data first.\n",
    "\n",
    "Random Forest does not need scaling as we only care about splitting the data to leafs based on information gain or impurity (entropy or gini) which is robust to data being in different units of measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler      = StandardScaler()\n",
    "X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "X_val_scaled    = scaler.transform(X_val)\n",
    "X_test_scaled   = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow implementation: building the Neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(X_train.shape[1],)),    \n",
    "        Dense(25, activation='sigmoid', name = 'layer1'),\n",
    "        Dense(1, activation='sigmoid', name = 'output')\n",
    "    ], name = \"ann\" \n",
    ")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ann\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 25)                225       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6445 - accuracy: 0.6558 - val_loss: 0.6413 - val_accuracy: 0.6260\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.6497 - val_loss: 0.6272 - val_accuracy: 0.6341\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6436 - val_loss: 0.6164 - val_accuracy: 0.6341\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.6456 - val_loss: 0.6075 - val_accuracy: 0.6341\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.6517 - val_loss: 0.5988 - val_accuracy: 0.6504\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.6640 - val_loss: 0.5907 - val_accuracy: 0.6423\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.6721 - val_loss: 0.5828 - val_accuracy: 0.6748\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.6965 - val_loss: 0.5752 - val_accuracy: 0.7073\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7047 - val_loss: 0.5689 - val_accuracy: 0.7154\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7088 - val_loss: 0.5628 - val_accuracy: 0.7317\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7128 - val_loss: 0.5572 - val_accuracy: 0.7398\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7312 - val_loss: 0.5515 - val_accuracy: 0.7398\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7291 - val_loss: 0.5465 - val_accuracy: 0.7398\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7291 - val_loss: 0.5417 - val_accuracy: 0.7398\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7413 - val_loss: 0.5369 - val_accuracy: 0.7480\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7454 - val_loss: 0.5329 - val_accuracy: 0.7561\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7536 - val_loss: 0.5297 - val_accuracy: 0.7480\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7576 - val_loss: 0.5262 - val_accuracy: 0.7480\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7597 - val_loss: 0.5233 - val_accuracy: 0.7561\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7597 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7637 - val_loss: 0.5171 - val_accuracy: 0.7480\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7597 - val_loss: 0.5144 - val_accuracy: 0.7317\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7617 - val_loss: 0.5118 - val_accuracy: 0.7317\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7576 - val_loss: 0.5095 - val_accuracy: 0.7317\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7597 - val_loss: 0.5075 - val_accuracy: 0.7317\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7597 - val_loss: 0.5058 - val_accuracy: 0.7317\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7637 - val_loss: 0.5044 - val_accuracy: 0.7317\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7637 - val_loss: 0.5024 - val_accuracy: 0.7236\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7637 - val_loss: 0.5009 - val_accuracy: 0.7236\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7637 - val_loss: 0.4996 - val_accuracy: 0.7236\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7658 - val_loss: 0.4985 - val_accuracy: 0.7317\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7637 - val_loss: 0.4972 - val_accuracy: 0.7398\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7658 - val_loss: 0.4960 - val_accuracy: 0.7317\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7678 - val_loss: 0.4953 - val_accuracy: 0.7480\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7658 - val_loss: 0.4942 - val_accuracy: 0.7398\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7658 - val_loss: 0.4935 - val_accuracy: 0.7561\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7678 - val_loss: 0.4924 - val_accuracy: 0.7561\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7678 - val_loss: 0.4913 - val_accuracy: 0.7480\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7699 - val_loss: 0.4907 - val_accuracy: 0.7317\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7699 - val_loss: 0.4900 - val_accuracy: 0.7480\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7739 - val_loss: 0.4895 - val_accuracy: 0.7398\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7480\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7739 - val_loss: 0.4884 - val_accuracy: 0.7398\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7739 - val_loss: 0.4880 - val_accuracy: 0.7398\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7398\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7800 - val_loss: 0.4875 - val_accuracy: 0.7398\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7800 - val_loss: 0.4872 - val_accuracy: 0.7398\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7821 - val_loss: 0.4866 - val_accuracy: 0.7398\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7800 - val_loss: 0.4860 - val_accuracy: 0.7398\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7800 - val_loss: 0.4860 - val_accuracy: 0.7398\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7821 - val_loss: 0.4859 - val_accuracy: 0.7317\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7800 - val_loss: 0.4860 - val_accuracy: 0.7317\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7780 - val_loss: 0.4860 - val_accuracy: 0.7317\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7800 - val_loss: 0.4854 - val_accuracy: 0.7317\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7800 - val_loss: 0.4853 - val_accuracy: 0.7398\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7821 - val_loss: 0.4843 - val_accuracy: 0.7317\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7841 - val_loss: 0.4844 - val_accuracy: 0.7317\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.7862 - val_loss: 0.4841 - val_accuracy: 0.7398\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7841 - val_loss: 0.4836 - val_accuracy: 0.7398\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7821 - val_loss: 0.4837 - val_accuracy: 0.7398\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7821 - val_loss: 0.4835 - val_accuracy: 0.7398\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7821 - val_loss: 0.4837 - val_accuracy: 0.7398\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7841 - val_loss: 0.4832 - val_accuracy: 0.7398\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7841 - val_loss: 0.4832 - val_accuracy: 0.7398\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7841 - val_loss: 0.4827 - val_accuracy: 0.7398\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7841 - val_loss: 0.4827 - val_accuracy: 0.7398\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7841 - val_loss: 0.4828 - val_accuracy: 0.7398\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7841 - val_loss: 0.4828 - val_accuracy: 0.7398\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7841 - val_loss: 0.4830 - val_accuracy: 0.7398\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7862 - val_loss: 0.4830 - val_accuracy: 0.7398\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7841 - val_loss: 0.4828 - val_accuracy: 0.7398\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7841 - val_loss: 0.4826 - val_accuracy: 0.7398\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7841 - val_loss: 0.4822 - val_accuracy: 0.7480\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7821 - val_loss: 0.4826 - val_accuracy: 0.7398\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7841 - val_loss: 0.4825 - val_accuracy: 0.7398\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7841 - val_loss: 0.4828 - val_accuracy: 0.7398\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7862 - val_loss: 0.4826 - val_accuracy: 0.7398\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7841 - val_loss: 0.4826 - val_accuracy: 0.7398\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7862 - val_loss: 0.4825 - val_accuracy: 0.7398\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7841 - val_loss: 0.4823 - val_accuracy: 0.7398\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7841 - val_loss: 0.4820 - val_accuracy: 0.7398\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7841 - val_loss: 0.4819 - val_accuracy: 0.7480\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7841 - val_loss: 0.4815 - val_accuracy: 0.7480\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7841 - val_loss: 0.4817 - val_accuracy: 0.7480\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7841 - val_loss: 0.4819 - val_accuracy: 0.7398\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7862 - val_loss: 0.4819 - val_accuracy: 0.7398\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7841 - val_loss: 0.4821 - val_accuracy: 0.7398\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4821 - val_accuracy: 0.7398\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7821 - val_loss: 0.4816 - val_accuracy: 0.7398\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7862 - val_loss: 0.4816 - val_accuracy: 0.7398\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7841 - val_loss: 0.4813 - val_accuracy: 0.7480\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7841 - val_loss: 0.4815 - val_accuracy: 0.7480\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7821 - val_loss: 0.4819 - val_accuracy: 0.7398\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7780 - val_loss: 0.4820 - val_accuracy: 0.7398\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4819 - val_accuracy: 0.7398\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7780 - val_loss: 0.4816 - val_accuracy: 0.7398\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4814 - val_accuracy: 0.7480\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7862 - val_loss: 0.4815 - val_accuracy: 0.7480\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7821 - val_loss: 0.4812 - val_accuracy: 0.7561\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7821 - val_loss: 0.4814 - val_accuracy: 0.7480\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7821 - val_loss: 0.4811 - val_accuracy: 0.7561\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7780 - val_loss: 0.4812 - val_accuracy: 0.7480\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7821 - val_loss: 0.4810 - val_accuracy: 0.7561\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7821 - val_loss: 0.4812 - val_accuracy: 0.7480\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7800 - val_loss: 0.4808 - val_accuracy: 0.7480\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4807 - val_accuracy: 0.7561\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7821 - val_loss: 0.4809 - val_accuracy: 0.7561\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4809 - val_accuracy: 0.7561\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4808 - val_accuracy: 0.7561\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7821 - val_loss: 0.4807 - val_accuracy: 0.7561\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7821 - val_loss: 0.4809 - val_accuracy: 0.7561\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7821 - val_loss: 0.4814 - val_accuracy: 0.7561\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7821 - val_loss: 0.4807 - val_accuracy: 0.7561\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7800 - val_loss: 0.4803 - val_accuracy: 0.7561\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7800 - val_loss: 0.4804 - val_accuracy: 0.7561\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7800 - val_loss: 0.4799 - val_accuracy: 0.7561\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7780 - val_loss: 0.4798 - val_accuracy: 0.7561\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7780 - val_loss: 0.4798 - val_accuracy: 0.7561\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7800 - val_loss: 0.4797 - val_accuracy: 0.7561\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.4796 - val_accuracy: 0.7561\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7780 - val_loss: 0.4798 - val_accuracy: 0.7561\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.4800 - val_accuracy: 0.7561\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.4799 - val_accuracy: 0.7561\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7780 - val_loss: 0.4799 - val_accuracy: 0.7561\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7780 - val_loss: 0.4797 - val_accuracy: 0.7561\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7800 - val_loss: 0.4799 - val_accuracy: 0.7561\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7800 - val_loss: 0.4799 - val_accuracy: 0.7561\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7800 - val_loss: 0.4800 - val_accuracy: 0.7561\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7800 - val_loss: 0.4798 - val_accuracy: 0.7642\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7780 - val_loss: 0.4796 - val_accuracy: 0.7642\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7739 - val_loss: 0.4798 - val_accuracy: 0.7642\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7780 - val_loss: 0.4793 - val_accuracy: 0.7642\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7780 - val_loss: 0.4796 - val_accuracy: 0.7642\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7800 - val_loss: 0.4798 - val_accuracy: 0.7642\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7821 - val_loss: 0.4798 - val_accuracy: 0.7561\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7800 - val_loss: 0.4801 - val_accuracy: 0.7642\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7821 - val_loss: 0.4800 - val_accuracy: 0.7642\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7739 - val_loss: 0.4796 - val_accuracy: 0.7642\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7800 - val_loss: 0.4800 - val_accuracy: 0.7642\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7780 - val_loss: 0.4799 - val_accuracy: 0.7642\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7780 - val_loss: 0.4794 - val_accuracy: 0.7642\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7739 - val_loss: 0.4795 - val_accuracy: 0.7642\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7739 - val_loss: 0.4792 - val_accuracy: 0.7642\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7739 - val_loss: 0.4794 - val_accuracy: 0.7642\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.4791 - val_accuracy: 0.7642\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7739 - val_loss: 0.4787 - val_accuracy: 0.7642\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7780 - val_loss: 0.4790 - val_accuracy: 0.7642\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7780 - val_loss: 0.4784 - val_accuracy: 0.7642\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4781 - val_accuracy: 0.7561\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7719 - val_loss: 0.4786 - val_accuracy: 0.7642\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7739 - val_loss: 0.4785 - val_accuracy: 0.7642\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7739 - val_loss: 0.4784 - val_accuracy: 0.7561\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7699 - val_loss: 0.4783 - val_accuracy: 0.7561\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7719 - val_loss: 0.4788 - val_accuracy: 0.7642\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7821 - val_loss: 0.4790 - val_accuracy: 0.7642\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7780 - val_loss: 0.4788 - val_accuracy: 0.7642\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4785 - val_accuracy: 0.7642\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7780 - val_loss: 0.4786 - val_accuracy: 0.7642\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7739 - val_loss: 0.4784 - val_accuracy: 0.7642\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7780 - val_loss: 0.4785 - val_accuracy: 0.7642\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7800 - val_loss: 0.4787 - val_accuracy: 0.7642\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7821 - val_loss: 0.4788 - val_accuracy: 0.7642\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7800 - val_loss: 0.4781 - val_accuracy: 0.7642\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7821 - val_loss: 0.4783 - val_accuracy: 0.7642\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7800 - val_loss: 0.4780 - val_accuracy: 0.7642\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7780 - val_loss: 0.4782 - val_accuracy: 0.7642\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4623 - accuracy: 0.7800 - val_loss: 0.4785 - val_accuracy: 0.7642\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7821 - val_loss: 0.4789 - val_accuracy: 0.7642\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7739 - val_loss: 0.4784 - val_accuracy: 0.7642\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7780 - val_loss: 0.4786 - val_accuracy: 0.7642\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7841 - val_loss: 0.4786 - val_accuracy: 0.7642\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7780 - val_loss: 0.4789 - val_accuracy: 0.7642\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7780 - val_loss: 0.4789 - val_accuracy: 0.7642\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4782 - val_accuracy: 0.7642\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4784 - val_accuracy: 0.7642\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4787 - val_accuracy: 0.7642\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4787 - val_accuracy: 0.7642\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4789 - val_accuracy: 0.7642\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4787 - val_accuracy: 0.7642\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7739 - val_loss: 0.4788 - val_accuracy: 0.7642\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4788 - val_accuracy: 0.7642\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4788 - val_accuracy: 0.7642\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4784 - val_accuracy: 0.7642\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.4786 - val_accuracy: 0.7642\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7739 - val_loss: 0.4783 - val_accuracy: 0.7642\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4780 - val_accuracy: 0.7642\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7780 - val_loss: 0.4777 - val_accuracy: 0.7642\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7800 - val_loss: 0.4773 - val_accuracy: 0.7642\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4777 - val_accuracy: 0.7642\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.4777 - val_accuracy: 0.7642\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7739 - val_loss: 0.4773 - val_accuracy: 0.7642\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7739 - val_loss: 0.4775 - val_accuracy: 0.7642\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7739 - val_loss: 0.4777 - val_accuracy: 0.7642\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4778 - val_accuracy: 0.7642\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7760 - val_loss: 0.4781 - val_accuracy: 0.7642\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.4781 - val_accuracy: 0.7642\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7739 - val_loss: 0.4780 - val_accuracy: 0.7642\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7760 - val_loss: 0.4780 - val_accuracy: 0.7642\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.4782 - val_accuracy: 0.7642\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4782 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "ann.compile(\n",
    "    loss     = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer= tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = ann.fit(\n",
    "    X_train2_scaled,y_train2,\n",
    "    epochs=200,\n",
    "    validation_data=(X_val_scaled, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the available keys in the history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Create a plot with train and validation loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history[\"loss\"], 'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(history.history[\"val_loss\"], 'b', marker='.', label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss keeps decreasing but slowsdown around 200 epochs. The differences are very small. Validation loss stops decreasing. Model doesnt look to benefit more with further training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# soft prediction - probabilities of having diabetes\n",
    "\n",
    "y_preds = ann.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard prediction - 1:have diabetes or 0: does not have\n",
    "y_preds_binary = np.where(y_preds >= 0.5, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ROC-AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.818\n",
      "roc-auc is 0.881\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_preds_binary)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_preds )))\n",
    "\n",
    "plot_roc(y_test, y_preds , 'NN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the single layer neural network outperformed the baseline random forest model with a larger roc-auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Experimenting with different network structures: learning rates, activation functions, gradient descent optiomisation algorithms, numbers of epochs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6788 - accuracy: 0.6110 - val_loss: 0.6522 - val_accuracy: 0.6748\n",
      "Epoch 2/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.6253 - val_loss: 0.6502 - val_accuracy: 0.6992\n",
      "Epoch 3/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6744 - accuracy: 0.6375 - val_loss: 0.6484 - val_accuracy: 0.7073\n",
      "Epoch 4/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6477 - val_loss: 0.6465 - val_accuracy: 0.7073\n",
      "Epoch 5/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.6721 - val_loss: 0.6447 - val_accuracy: 0.7154\n",
      "Epoch 6/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6684 - accuracy: 0.6741 - val_loss: 0.6428 - val_accuracy: 0.7317\n",
      "Epoch 7/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6664 - accuracy: 0.6741 - val_loss: 0.6410 - val_accuracy: 0.7398\n",
      "Epoch 8/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.6864 - val_loss: 0.6393 - val_accuracy: 0.7480\n",
      "Epoch 9/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6925 - val_loss: 0.6375 - val_accuracy: 0.7561\n",
      "Epoch 10/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6606 - accuracy: 0.6986 - val_loss: 0.6358 - val_accuracy: 0.7642\n",
      "Epoch 11/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.7026 - val_loss: 0.6340 - val_accuracy: 0.7724\n",
      "Epoch 12/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6569 - accuracy: 0.7108 - val_loss: 0.6323 - val_accuracy: 0.7805\n",
      "Epoch 13/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.7128 - val_loss: 0.6305 - val_accuracy: 0.7805\n",
      "Epoch 14/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.7149 - val_loss: 0.6288 - val_accuracy: 0.7724\n",
      "Epoch 15/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6512 - accuracy: 0.7169 - val_loss: 0.6273 - val_accuracy: 0.7805\n",
      "Epoch 16/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.7210 - val_loss: 0.6256 - val_accuracy: 0.7805\n",
      "Epoch 17/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.7210 - val_loss: 0.6239 - val_accuracy: 0.7805\n",
      "Epoch 18/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7210 - val_loss: 0.6221 - val_accuracy: 0.7805\n",
      "Epoch 19/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.7230 - val_loss: 0.6204 - val_accuracy: 0.7805\n",
      "Epoch 20/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7210 - val_loss: 0.6187 - val_accuracy: 0.7805\n",
      "Epoch 21/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.7271 - val_loss: 0.6171 - val_accuracy: 0.7805\n",
      "Epoch 22/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.7312 - val_loss: 0.6155 - val_accuracy: 0.7805\n",
      "Epoch 23/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.7352 - val_loss: 0.6139 - val_accuracy: 0.7805\n",
      "Epoch 24/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.7393 - val_loss: 0.6122 - val_accuracy: 0.7805\n",
      "Epoch 25/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.7454 - val_loss: 0.6107 - val_accuracy: 0.7805\n",
      "Epoch 26/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7495 - val_loss: 0.6090 - val_accuracy: 0.7805\n",
      "Epoch 27/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.7495 - val_loss: 0.6076 - val_accuracy: 0.7805\n",
      "Epoch 28/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.7515 - val_loss: 0.6061 - val_accuracy: 0.7805\n",
      "Epoch 29/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.7515 - val_loss: 0.6045 - val_accuracy: 0.7805\n",
      "Epoch 30/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.7515 - val_loss: 0.6031 - val_accuracy: 0.7805\n",
      "Epoch 31/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.7515 - val_loss: 0.6016 - val_accuracy: 0.7805\n",
      "Epoch 32/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6219 - accuracy: 0.7515 - val_loss: 0.6001 - val_accuracy: 0.7805\n",
      "Epoch 33/1500\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6203 - accuracy: 0.7536 - val_loss: 0.5986 - val_accuracy: 0.7805\n",
      "Epoch 34/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.7536 - val_loss: 0.5970 - val_accuracy: 0.7805\n",
      "Epoch 35/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.7536 - val_loss: 0.5955 - val_accuracy: 0.7805\n",
      "Epoch 36/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.7556 - val_loss: 0.5941 - val_accuracy: 0.7805\n",
      "Epoch 37/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.7515 - val_loss: 0.5925 - val_accuracy: 0.7805\n",
      "Epoch 38/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.7576 - val_loss: 0.5910 - val_accuracy: 0.7805\n",
      "Epoch 39/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7556 - val_loss: 0.5895 - val_accuracy: 0.7805\n",
      "Epoch 40/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7576 - val_loss: 0.5880 - val_accuracy: 0.7805\n",
      "Epoch 41/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7597 - val_loss: 0.5864 - val_accuracy: 0.7805\n",
      "Epoch 42/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.7576 - val_loss: 0.5849 - val_accuracy: 0.7805\n",
      "Epoch 43/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7576 - val_loss: 0.5835 - val_accuracy: 0.7805\n",
      "Epoch 44/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.7576 - val_loss: 0.5820 - val_accuracy: 0.7805\n",
      "Epoch 45/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7576 - val_loss: 0.5806 - val_accuracy: 0.7805\n",
      "Epoch 46/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5996 - accuracy: 0.7576 - val_loss: 0.5791 - val_accuracy: 0.7805\n",
      "Epoch 47/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7576 - val_loss: 0.5777 - val_accuracy: 0.7805\n",
      "Epoch 48/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7556 - val_loss: 0.5764 - val_accuracy: 0.7805\n",
      "Epoch 49/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7556 - val_loss: 0.5750 - val_accuracy: 0.7805\n",
      "Epoch 50/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7556 - val_loss: 0.5736 - val_accuracy: 0.7805\n",
      "Epoch 51/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.7556 - val_loss: 0.5723 - val_accuracy: 0.7805\n",
      "Epoch 52/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7556 - val_loss: 0.5710 - val_accuracy: 0.7805\n",
      "Epoch 53/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.7576 - val_loss: 0.5697 - val_accuracy: 0.7724\n",
      "Epoch 54/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.7556 - val_loss: 0.5684 - val_accuracy: 0.7805\n",
      "Epoch 55/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.7556 - val_loss: 0.5672 - val_accuracy: 0.7724\n",
      "Epoch 56/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.7556 - val_loss: 0.5660 - val_accuracy: 0.7724\n",
      "Epoch 57/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7556 - val_loss: 0.5648 - val_accuracy: 0.7805\n",
      "Epoch 58/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7556 - val_loss: 0.5636 - val_accuracy: 0.7805\n",
      "Epoch 59/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.7556 - val_loss: 0.5623 - val_accuracy: 0.7805\n",
      "Epoch 60/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7576 - val_loss: 0.5611 - val_accuracy: 0.7805\n",
      "Epoch 61/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7617 - val_loss: 0.5600 - val_accuracy: 0.7724\n",
      "Epoch 62/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7617 - val_loss: 0.5589 - val_accuracy: 0.7724\n",
      "Epoch 63/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7617 - val_loss: 0.5578 - val_accuracy: 0.7724\n",
      "Epoch 64/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7617 - val_loss: 0.5567 - val_accuracy: 0.7724\n",
      "Epoch 65/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7617 - val_loss: 0.5556 - val_accuracy: 0.7642\n",
      "Epoch 66/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7637 - val_loss: 0.5546 - val_accuracy: 0.7724\n",
      "Epoch 67/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7637 - val_loss: 0.5535 - val_accuracy: 0.7724\n",
      "Epoch 68/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7658 - val_loss: 0.5525 - val_accuracy: 0.7724\n",
      "Epoch 69/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7658 - val_loss: 0.5515 - val_accuracy: 0.7805\n",
      "Epoch 70/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7658 - val_loss: 0.5506 - val_accuracy: 0.7805\n",
      "Epoch 71/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7678 - val_loss: 0.5496 - val_accuracy: 0.7805\n",
      "Epoch 72/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7699 - val_loss: 0.5486 - val_accuracy: 0.7805\n",
      "Epoch 73/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7699 - val_loss: 0.5478 - val_accuracy: 0.7805\n",
      "Epoch 74/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7699 - val_loss: 0.5470 - val_accuracy: 0.7805\n",
      "Epoch 75/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7699 - val_loss: 0.5462 - val_accuracy: 0.7805\n",
      "Epoch 76/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5586 - accuracy: 0.7699 - val_loss: 0.5452 - val_accuracy: 0.7805\n",
      "Epoch 77/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7699 - val_loss: 0.5443 - val_accuracy: 0.7805\n",
      "Epoch 78/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7719 - val_loss: 0.5435 - val_accuracy: 0.7805\n",
      "Epoch 79/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7699 - val_loss: 0.5426 - val_accuracy: 0.7805\n",
      "Epoch 80/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7719 - val_loss: 0.5418 - val_accuracy: 0.7805\n",
      "Epoch 81/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7760 - val_loss: 0.5409 - val_accuracy: 0.7805\n",
      "Epoch 82/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7780 - val_loss: 0.5400 - val_accuracy: 0.7805\n",
      "Epoch 83/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7800 - val_loss: 0.5392 - val_accuracy: 0.7805\n",
      "Epoch 84/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7780 - val_loss: 0.5384 - val_accuracy: 0.7805\n",
      "Epoch 85/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7780 - val_loss: 0.5377 - val_accuracy: 0.7805\n",
      "Epoch 86/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7780 - val_loss: 0.5369 - val_accuracy: 0.7805\n",
      "Epoch 87/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7800 - val_loss: 0.5361 - val_accuracy: 0.7805\n",
      "Epoch 88/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7800 - val_loss: 0.5354 - val_accuracy: 0.7805\n",
      "Epoch 89/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7800 - val_loss: 0.5347 - val_accuracy: 0.7724\n",
      "Epoch 90/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7821 - val_loss: 0.5339 - val_accuracy: 0.7724\n",
      "Epoch 91/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7800 - val_loss: 0.5331 - val_accuracy: 0.7724\n",
      "Epoch 92/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7800 - val_loss: 0.5324 - val_accuracy: 0.7724\n",
      "Epoch 93/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7760 - val_loss: 0.5317 - val_accuracy: 0.7724\n",
      "Epoch 94/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7821 - val_loss: 0.5309 - val_accuracy: 0.7642\n",
      "Epoch 95/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7800 - val_loss: 0.5303 - val_accuracy: 0.7724\n",
      "Epoch 96/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7800 - val_loss: 0.5297 - val_accuracy: 0.7642\n",
      "Epoch 97/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.7821 - val_loss: 0.5290 - val_accuracy: 0.7642\n",
      "Epoch 98/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7841 - val_loss: 0.5285 - val_accuracy: 0.7724\n",
      "Epoch 99/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7800 - val_loss: 0.5279 - val_accuracy: 0.7642\n",
      "Epoch 100/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7841 - val_loss: 0.5272 - val_accuracy: 0.7642\n",
      "Epoch 101/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7821 - val_loss: 0.5266 - val_accuracy: 0.7642\n",
      "Epoch 102/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7821 - val_loss: 0.5261 - val_accuracy: 0.7724\n",
      "Epoch 103/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7841 - val_loss: 0.5254 - val_accuracy: 0.7642\n",
      "Epoch 104/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7821 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
      "Epoch 105/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7821 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
      "Epoch 106/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7821 - val_loss: 0.5238 - val_accuracy: 0.7561\n",
      "Epoch 107/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7780 - val_loss: 0.5233 - val_accuracy: 0.7561\n",
      "Epoch 108/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7739 - val_loss: 0.5229 - val_accuracy: 0.7561\n",
      "Epoch 109/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7780 - val_loss: 0.5223 - val_accuracy: 0.7561\n",
      "Epoch 110/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7780 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
      "Epoch 111/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7739 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
      "Epoch 112/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7739 - val_loss: 0.5207 - val_accuracy: 0.7561\n",
      "Epoch 113/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5240 - accuracy: 0.7699 - val_loss: 0.5202 - val_accuracy: 0.7561\n",
      "Epoch 114/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5232 - accuracy: 0.7719 - val_loss: 0.5198 - val_accuracy: 0.7561\n",
      "Epoch 115/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7739 - val_loss: 0.5193 - val_accuracy: 0.7561\n",
      "Epoch 116/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7719 - val_loss: 0.5188 - val_accuracy: 0.7561\n",
      "Epoch 117/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7699 - val_loss: 0.5183 - val_accuracy: 0.7561\n",
      "Epoch 118/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7699 - val_loss: 0.5179 - val_accuracy: 0.7561\n",
      "Epoch 119/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7678 - val_loss: 0.5173 - val_accuracy: 0.7561\n",
      "Epoch 120/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7699 - val_loss: 0.5169 - val_accuracy: 0.7561\n",
      "Epoch 121/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7678 - val_loss: 0.5165 - val_accuracy: 0.7561\n",
      "Epoch 122/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7699 - val_loss: 0.5160 - val_accuracy: 0.7561\n",
      "Epoch 123/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7699 - val_loss: 0.5157 - val_accuracy: 0.7561\n",
      "Epoch 124/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7719 - val_loss: 0.5152 - val_accuracy: 0.7561\n",
      "Epoch 125/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7699 - val_loss: 0.5149 - val_accuracy: 0.7561\n",
      "Epoch 126/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7699 - val_loss: 0.5145 - val_accuracy: 0.7561\n",
      "Epoch 127/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7699 - val_loss: 0.5141 - val_accuracy: 0.7561\n",
      "Epoch 128/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7699 - val_loss: 0.5137 - val_accuracy: 0.7561\n",
      "Epoch 129/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7719 - val_loss: 0.5133 - val_accuracy: 0.7561\n",
      "Epoch 130/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7719 - val_loss: 0.5130 - val_accuracy: 0.7561\n",
      "Epoch 131/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7719 - val_loss: 0.5126 - val_accuracy: 0.7561\n",
      "Epoch 132/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7719 - val_loss: 0.5123 - val_accuracy: 0.7561\n",
      "Epoch 133/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7739 - val_loss: 0.5121 - val_accuracy: 0.7561\n",
      "Epoch 134/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7739 - val_loss: 0.5118 - val_accuracy: 0.7561\n",
      "Epoch 135/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7561\n",
      "Epoch 136/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7642\n",
      "Epoch 137/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7739 - val_loss: 0.5108 - val_accuracy: 0.7642\n",
      "Epoch 138/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7739 - val_loss: 0.5104 - val_accuracy: 0.7642\n",
      "Epoch 139/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7739 - val_loss: 0.5101 - val_accuracy: 0.7642\n",
      "Epoch 140/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7739 - val_loss: 0.5098 - val_accuracy: 0.7642\n",
      "Epoch 141/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7739 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
      "Epoch 142/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7739 - val_loss: 0.5092 - val_accuracy: 0.7642\n",
      "Epoch 143/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7642\n",
      "Epoch 144/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
      "Epoch 145/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7642\n",
      "Epoch 146/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
      "Epoch 147/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7642\n",
      "Epoch 148/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7719 - val_loss: 0.5073 - val_accuracy: 0.7642\n",
      "Epoch 149/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
      "Epoch 150/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7739 - val_loss: 0.5067 - val_accuracy: 0.7642\n",
      "Epoch 151/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7739 - val_loss: 0.5067 - val_accuracy: 0.7642\n",
      "Epoch 152/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7739 - val_loss: 0.5065 - val_accuracy: 0.7642\n",
      "Epoch 153/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7760 - val_loss: 0.5062 - val_accuracy: 0.7642\n",
      "Epoch 154/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7739 - val_loss: 0.5059 - val_accuracy: 0.7642\n",
      "Epoch 155/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7642\n",
      "Epoch 156/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7780 - val_loss: 0.5054 - val_accuracy: 0.7642\n",
      "Epoch 157/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7780 - val_loss: 0.5052 - val_accuracy: 0.7642\n",
      "Epoch 158/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7780 - val_loss: 0.5051 - val_accuracy: 0.7724\n",
      "Epoch 159/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.7800 - val_loss: 0.5049 - val_accuracy: 0.7724\n",
      "Epoch 160/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7800 - val_loss: 0.5048 - val_accuracy: 0.7724\n",
      "Epoch 161/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7800 - val_loss: 0.5047 - val_accuracy: 0.7724\n",
      "Epoch 162/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7800 - val_loss: 0.5045 - val_accuracy: 0.7724\n",
      "Epoch 163/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7800 - val_loss: 0.5044 - val_accuracy: 0.7724\n",
      "Epoch 164/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7800 - val_loss: 0.5042 - val_accuracy: 0.7724\n",
      "Epoch 165/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7800 - val_loss: 0.5040 - val_accuracy: 0.7724\n",
      "Epoch 166/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7821 - val_loss: 0.5038 - val_accuracy: 0.7724\n",
      "Epoch 167/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7724\n",
      "Epoch 168/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
      "Epoch 169/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7821 - val_loss: 0.5034 - val_accuracy: 0.7724\n",
      "Epoch 170/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7841 - val_loss: 0.5033 - val_accuracy: 0.7724\n",
      "Epoch 171/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7841 - val_loss: 0.5032 - val_accuracy: 0.7724\n",
      "Epoch 172/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7841 - val_loss: 0.5030 - val_accuracy: 0.7724\n",
      "Epoch 173/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7821 - val_loss: 0.5028 - val_accuracy: 0.7724\n",
      "Epoch 174/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7841 - val_loss: 0.5027 - val_accuracy: 0.7724\n",
      "Epoch 175/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7821 - val_loss: 0.5026 - val_accuracy: 0.7724\n",
      "Epoch 176/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7821 - val_loss: 0.5025 - val_accuracy: 0.7724\n",
      "Epoch 177/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7841 - val_loss: 0.5025 - val_accuracy: 0.7724\n",
      "Epoch 178/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7821 - val_loss: 0.5023 - val_accuracy: 0.7724\n",
      "Epoch 179/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7841 - val_loss: 0.5022 - val_accuracy: 0.7724\n",
      "Epoch 180/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7841 - val_loss: 0.5021 - val_accuracy: 0.7724\n",
      "Epoch 181/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7821 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
      "Epoch 182/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7821 - val_loss: 0.5018 - val_accuracy: 0.7724\n",
      "Epoch 183/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7821 - val_loss: 0.5017 - val_accuracy: 0.7805\n",
      "Epoch 184/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7821 - val_loss: 0.5015 - val_accuracy: 0.7805\n",
      "Epoch 185/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7821 - val_loss: 0.5013 - val_accuracy: 0.7724\n",
      "Epoch 186/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7821 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
      "Epoch 187/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7821 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
      "Epoch 188/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7821 - val_loss: 0.5010 - val_accuracy: 0.7805\n",
      "Epoch 189/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7821 - val_loss: 0.5010 - val_accuracy: 0.7805\n",
      "Epoch 190/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7821 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
      "Epoch 191/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7821 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
      "Epoch 192/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7821 - val_loss: 0.5008 - val_accuracy: 0.7805\n",
      "Epoch 193/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7821 - val_loss: 0.5007 - val_accuracy: 0.7805\n",
      "Epoch 194/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7821 - val_loss: 0.5006 - val_accuracy: 0.7805\n",
      "Epoch 195/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7821 - val_loss: 0.5005 - val_accuracy: 0.7805\n",
      "Epoch 196/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7821 - val_loss: 0.5004 - val_accuracy: 0.7805\n",
      "Epoch 197/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7821 - val_loss: 0.5003 - val_accuracy: 0.7805\n",
      "Epoch 198/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7821 - val_loss: 0.5002 - val_accuracy: 0.7805\n",
      "Epoch 199/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7821 - val_loss: 0.5001 - val_accuracy: 0.7805\n",
      "Epoch 200/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7821 - val_loss: 0.5000 - val_accuracy: 0.7805\n",
      "Epoch 201/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7821 - val_loss: 0.5000 - val_accuracy: 0.7805\n",
      "Epoch 202/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7821 - val_loss: 0.4999 - val_accuracy: 0.7724\n",
      "Epoch 203/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7821 - val_loss: 0.4998 - val_accuracy: 0.7724\n",
      "Epoch 204/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4830 - accuracy: 0.7821 - val_loss: 0.4997 - val_accuracy: 0.7805\n",
      "Epoch 205/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7821 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
      "Epoch 206/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7841 - val_loss: 0.4995 - val_accuracy: 0.7805\n",
      "Epoch 207/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7821 - val_loss: 0.4994 - val_accuracy: 0.7805\n",
      "Epoch 208/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7841 - val_loss: 0.4993 - val_accuracy: 0.7805\n",
      "Epoch 209/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7841 - val_loss: 0.4992 - val_accuracy: 0.7805\n",
      "Epoch 210/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7841 - val_loss: 0.4992 - val_accuracy: 0.7805\n",
      "Epoch 211/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7841 - val_loss: 0.4991 - val_accuracy: 0.7805\n",
      "Epoch 212/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7841 - val_loss: 0.4990 - val_accuracy: 0.7805\n",
      "Epoch 213/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7841 - val_loss: 0.4990 - val_accuracy: 0.7805\n",
      "Epoch 214/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7841 - val_loss: 0.4989 - val_accuracy: 0.7805\n",
      "Epoch 215/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7841 - val_loss: 0.4988 - val_accuracy: 0.7805\n",
      "Epoch 216/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7821 - val_loss: 0.4988 - val_accuracy: 0.7805\n",
      "Epoch 217/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7841 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
      "Epoch 218/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7841 - val_loss: 0.4985 - val_accuracy: 0.7805\n",
      "Epoch 219/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7841 - val_loss: 0.4986 - val_accuracy: 0.7805\n",
      "Epoch 220/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7841 - val_loss: 0.4985 - val_accuracy: 0.7805\n",
      "Epoch 221/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7821 - val_loss: 0.4984 - val_accuracy: 0.7805\n",
      "Epoch 222/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7821 - val_loss: 0.4983 - val_accuracy: 0.7805\n",
      "Epoch 223/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7821 - val_loss: 0.4982 - val_accuracy: 0.7805\n",
      "Epoch 224/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7821 - val_loss: 0.4981 - val_accuracy: 0.7805\n",
      "Epoch 225/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7821 - val_loss: 0.4980 - val_accuracy: 0.7805\n",
      "Epoch 226/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7821 - val_loss: 0.4979 - val_accuracy: 0.7805\n",
      "Epoch 227/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7821 - val_loss: 0.4979 - val_accuracy: 0.7805\n",
      "Epoch 228/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7841 - val_loss: 0.4979 - val_accuracy: 0.7805\n",
      "Epoch 229/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7821 - val_loss: 0.4978 - val_accuracy: 0.7724\n",
      "Epoch 230/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7805\n",
      "Epoch 231/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7841 - val_loss: 0.4975 - val_accuracy: 0.7805\n",
      "Epoch 232/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7841 - val_loss: 0.4974 - val_accuracy: 0.7805\n",
      "Epoch 233/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7821 - val_loss: 0.4972 - val_accuracy: 0.7805\n",
      "Epoch 234/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7821 - val_loss: 0.4971 - val_accuracy: 0.7805\n",
      "Epoch 235/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7821 - val_loss: 0.4970 - val_accuracy: 0.7805\n",
      "Epoch 236/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7841 - val_loss: 0.4970 - val_accuracy: 0.7805\n",
      "Epoch 237/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7841 - val_loss: 0.4967 - val_accuracy: 0.7805\n",
      "Epoch 238/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7805\n",
      "Epoch 239/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7862 - val_loss: 0.4965 - val_accuracy: 0.7724\n",
      "Epoch 240/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7724\n",
      "Epoch 241/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7724\n",
      "Epoch 242/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7862 - val_loss: 0.4963 - val_accuracy: 0.7724\n",
      "Epoch 243/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7902 - val_loss: 0.4962 - val_accuracy: 0.7724\n",
      "Epoch 244/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7724\n",
      "Epoch 245/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7902 - val_loss: 0.4960 - val_accuracy: 0.7724\n",
      "Epoch 246/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7724\n",
      "Epoch 247/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7902 - val_loss: 0.4959 - val_accuracy: 0.7724\n",
      "Epoch 248/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7805\n",
      "Epoch 249/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7902 - val_loss: 0.4958 - val_accuracy: 0.7805\n",
      "Epoch 250/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7902 - val_loss: 0.4958 - val_accuracy: 0.7805\n",
      "Epoch 251/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7805\n",
      "Epoch 252/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7805\n",
      "Epoch 253/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7805\n",
      "Epoch 254/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7902 - val_loss: 0.4956 - val_accuracy: 0.7805\n",
      "Epoch 255/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7902 - val_loss: 0.4955 - val_accuracy: 0.7805\n",
      "Epoch 256/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7902 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 257/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7902 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 258/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7902 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 259/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7923 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 260/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7923 - val_loss: 0.4950 - val_accuracy: 0.7805\n",
      "Epoch 261/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7902 - val_loss: 0.4950 - val_accuracy: 0.7805\n",
      "Epoch 262/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7902 - val_loss: 0.4950 - val_accuracy: 0.7805\n",
      "Epoch 263/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7923 - val_loss: 0.4949 - val_accuracy: 0.7805\n",
      "Epoch 264/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7923 - val_loss: 0.4948 - val_accuracy: 0.7805\n",
      "Epoch 265/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7923 - val_loss: 0.4948 - val_accuracy: 0.7805\n",
      "Epoch 266/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7902 - val_loss: 0.4948 - val_accuracy: 0.7805\n",
      "Epoch 267/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7923 - val_loss: 0.4949 - val_accuracy: 0.7805\n",
      "Epoch 268/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7882 - val_loss: 0.4948 - val_accuracy: 0.7805\n",
      "Epoch 269/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7963 - val_loss: 0.4948 - val_accuracy: 0.7724\n",
      "Epoch 270/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7943 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 271/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7963 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 272/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7943 - val_loss: 0.4946 - val_accuracy: 0.7724\n",
      "Epoch 273/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7963 - val_loss: 0.4947 - val_accuracy: 0.7724\n",
      "Epoch 274/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7963 - val_loss: 0.4946 - val_accuracy: 0.7724\n",
      "Epoch 275/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7963 - val_loss: 0.4945 - val_accuracy: 0.7805\n",
      "Epoch 276/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7963 - val_loss: 0.4945 - val_accuracy: 0.7805\n",
      "Epoch 277/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7943 - val_loss: 0.4944 - val_accuracy: 0.7805\n",
      "Epoch 278/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7963 - val_loss: 0.4944 - val_accuracy: 0.7805\n",
      "Epoch 279/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7902 - val_loss: 0.4943 - val_accuracy: 0.7805\n",
      "Epoch 280/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7923 - val_loss: 0.4942 - val_accuracy: 0.7805\n",
      "Epoch 281/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7943 - val_loss: 0.4942 - val_accuracy: 0.7724\n",
      "Epoch 282/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7963 - val_loss: 0.4941 - val_accuracy: 0.7805\n",
      "Epoch 283/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7943 - val_loss: 0.4940 - val_accuracy: 0.7805\n",
      "Epoch 284/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7923 - val_loss: 0.4940 - val_accuracy: 0.7805\n",
      "Epoch 285/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7943 - val_loss: 0.4941 - val_accuracy: 0.7724\n",
      "Epoch 286/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7923 - val_loss: 0.4940 - val_accuracy: 0.7724\n",
      "Epoch 287/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7943 - val_loss: 0.4939 - val_accuracy: 0.7724\n",
      "Epoch 288/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7963 - val_loss: 0.4940 - val_accuracy: 0.7724\n",
      "Epoch 289/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7923 - val_loss: 0.4939 - val_accuracy: 0.7724\n",
      "Epoch 290/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7923 - val_loss: 0.4939 - val_accuracy: 0.7724\n",
      "Epoch 291/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7923 - val_loss: 0.4938 - val_accuracy: 0.7724\n",
      "Epoch 292/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7963 - val_loss: 0.4938 - val_accuracy: 0.7724\n",
      "Epoch 293/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7943 - val_loss: 0.4937 - val_accuracy: 0.7805\n",
      "Epoch 294/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7902 - val_loss: 0.4936 - val_accuracy: 0.7805\n",
      "Epoch 295/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7923 - val_loss: 0.4934 - val_accuracy: 0.7805\n",
      "Epoch 296/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7923 - val_loss: 0.4934 - val_accuracy: 0.7805\n",
      "Epoch 297/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7923 - val_loss: 0.4934 - val_accuracy: 0.7805\n",
      "Epoch 298/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7902 - val_loss: 0.4934 - val_accuracy: 0.7805\n",
      "Epoch 299/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7902 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 300/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7902 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 301/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7902 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 302/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7923 - val_loss: 0.4932 - val_accuracy: 0.7805\n",
      "Epoch 303/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7902 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 304/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7923 - val_loss: 0.4933 - val_accuracy: 0.7805\n",
      "Epoch 305/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7923 - val_loss: 0.4932 - val_accuracy: 0.7805\n",
      "Epoch 306/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7902 - val_loss: 0.4932 - val_accuracy: 0.7805\n",
      "Epoch 307/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7923 - val_loss: 0.4932 - val_accuracy: 0.7805\n",
      "Epoch 308/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7902 - val_loss: 0.4931 - val_accuracy: 0.7805\n",
      "Epoch 309/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7923 - val_loss: 0.4931 - val_accuracy: 0.7805\n",
      "Epoch 310/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7902 - val_loss: 0.4931 - val_accuracy: 0.7805\n",
      "Epoch 311/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7805\n",
      "Epoch 312/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7923 - val_loss: 0.4929 - val_accuracy: 0.7805\n",
      "Epoch 313/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7805\n",
      "Epoch 314/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7902 - val_loss: 0.4929 - val_accuracy: 0.7805\n",
      "Epoch 315/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7902 - val_loss: 0.4927 - val_accuracy: 0.7805\n",
      "Epoch 316/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 317/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7805\n",
      "Epoch 318/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7805\n",
      "Epoch 319/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 320/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7902 - val_loss: 0.4928 - val_accuracy: 0.7805\n",
      "Epoch 321/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 322/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 323/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7902 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 324/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 325/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 326/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7902 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 327/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7923 - val_loss: 0.4926 - val_accuracy: 0.7886\n",
      "Epoch 328/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7923 - val_loss: 0.4926 - val_accuracy: 0.7805\n",
      "Epoch 329/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7902 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 330/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 331/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4576 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 332/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7923 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 333/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 334/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 335/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 336/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 337/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 338/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 339/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7923 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 340/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7923 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
      "Epoch 341/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 342/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 343/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 344/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 345/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 346/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7902 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 347/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7902 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 348/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7902 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 349/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7902 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 350/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 351/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7902 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 352/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7902 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 353/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7923 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 354/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7902 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 355/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7902 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 356/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7902 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 357/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7923 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 358/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7902 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 359/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7902 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 360/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7923 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 361/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7902 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 362/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7923 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 363/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7923 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 364/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7923 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 365/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7923 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 366/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7902 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 367/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7923 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 368/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7923 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 369/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7923 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 370/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7923 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 371/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 372/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 373/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 374/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 375/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 376/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 377/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 378/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 379/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 380/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 381/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 382/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7963 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 383/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 384/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 385/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 386/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 387/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7943 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
      "Epoch 388/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 389/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 390/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 391/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7943 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 392/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 393/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 394/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7943 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 395/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 396/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 397/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 398/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 399/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7943 - val_loss: 0.4936 - val_accuracy: 0.7886\n",
      "Epoch 400/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7943 - val_loss: 0.4934 - val_accuracy: 0.7886\n",
      "Epoch 401/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 402/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7943 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
      "Epoch 403/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 404/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 405/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 406/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7943 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
      "Epoch 407/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7943 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 408/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 409/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7963 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 410/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 411/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7943 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 412/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 413/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 414/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 415/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7943 - val_loss: 0.4934 - val_accuracy: 0.7886\n",
      "Epoch 416/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 417/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 418/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7943 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 419/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7963 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 420/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 421/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7943 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 422/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7963 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 423/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7963 - val_loss: 0.4933 - val_accuracy: 0.7886\n",
      "Epoch 424/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7984 - val_loss: 0.4933 - val_accuracy: 0.7967\n",
      "Epoch 425/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7963 - val_loss: 0.4934 - val_accuracy: 0.7967\n",
      "Epoch 426/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7984 - val_loss: 0.4933 - val_accuracy: 0.7967\n",
      "Epoch 427/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7984 - val_loss: 0.4932 - val_accuracy: 0.7967\n",
      "Epoch 428/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7984 - val_loss: 0.4933 - val_accuracy: 0.7967\n",
      "Epoch 429/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7963 - val_loss: 0.4932 - val_accuracy: 0.7967\n",
      "Epoch 430/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7984 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
      "Epoch 431/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7963 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
      "Epoch 432/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7963 - val_loss: 0.4931 - val_accuracy: 0.7967\n",
      "Epoch 433/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7984 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
      "Epoch 434/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7984 - val_loss: 0.4931 - val_accuracy: 0.7967\n",
      "Epoch 435/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.8024 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 436/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8004 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 437/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8004 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 438/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.8024 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 439/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7984 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 440/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.8024 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 441/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8024 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 442/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.8024 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 443/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8024 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 444/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8024 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 445/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8024 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 446/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8024 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
      "Epoch 447/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8024 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 448/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8024 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 449/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8024 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 450/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8024 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 451/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8024 - val_loss: 0.4925 - val_accuracy: 0.7967\n",
      "Epoch 452/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8045 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 453/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8045 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 454/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8045 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 455/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8024 - val_loss: 0.4922 - val_accuracy: 0.7967\n",
      "Epoch 456/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.8024 - val_loss: 0.4920 - val_accuracy: 0.7967\n",
      "Epoch 457/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8024 - val_loss: 0.4920 - val_accuracy: 0.7967\n",
      "Epoch 458/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8024 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 459/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7967\n",
      "Epoch 460/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8045 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 461/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8024 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 462/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8024 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
      "Epoch 463/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8045 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
      "Epoch 464/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8045 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 465/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8024 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 466/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8045 - val_loss: 0.4925 - val_accuracy: 0.7886\n",
      "Epoch 467/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7886\n",
      "Epoch 468/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 469/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7886\n",
      "Epoch 470/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 471/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 472/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 473/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 474/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 475/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 476/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8024 - val_loss: 0.4919 - val_accuracy: 0.7886\n",
      "Epoch 477/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8024 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 478/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 479/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8024 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 480/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8024 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 481/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8024 - val_loss: 0.4915 - val_accuracy: 0.7886\n",
      "Epoch 482/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8024 - val_loss: 0.4915 - val_accuracy: 0.7886\n",
      "Epoch 483/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8024 - val_loss: 0.4915 - val_accuracy: 0.7886\n",
      "Epoch 484/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8024 - val_loss: 0.4915 - val_accuracy: 0.7886\n",
      "Epoch 485/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 486/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.8024 - val_loss: 0.4916 - val_accuracy: 0.7886\n",
      "Epoch 487/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8024 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 488/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8024 - val_loss: 0.4916 - val_accuracy: 0.7886\n",
      "Epoch 489/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 490/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8024 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 491/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8004 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 492/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.8024 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 493/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 494/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8024 - val_loss: 0.4919 - val_accuracy: 0.7886\n",
      "Epoch 495/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8004 - val_loss: 0.4919 - val_accuracy: 0.7886\n",
      "Epoch 496/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.8024 - val_loss: 0.4913 - val_accuracy: 0.7886\n",
      "Epoch 497/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8004 - val_loss: 0.4914 - val_accuracy: 0.7886\n",
      "Epoch 498/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7984 - val_loss: 0.4914 - val_accuracy: 0.7886\n",
      "Epoch 499/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.8004 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 500/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8004 - val_loss: 0.4920 - val_accuracy: 0.7886\n",
      "Epoch 501/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.8004 - val_loss: 0.4921 - val_accuracy: 0.7886\n",
      "Epoch 502/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8004 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
      "Epoch 503/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8004 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 504/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 505/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 506/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 507/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 508/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 509/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8004 - val_loss: 0.4925 - val_accuracy: 0.7886\n",
      "Epoch 510/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 511/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 512/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 513/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8004 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 514/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8004 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
      "Epoch 515/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 516/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8004 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 517/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 518/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 519/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 520/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 521/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 522/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7984 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
      "Epoch 523/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7984 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
      "Epoch 524/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7984 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 525/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7984 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 526/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7886\n",
      "Epoch 527/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8004 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 528/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7984 - val_loss: 0.4920 - val_accuracy: 0.7886\n",
      "Epoch 529/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7984 - val_loss: 0.4921 - val_accuracy: 0.7886\n",
      "Epoch 530/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8024 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 531/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8024 - val_loss: 0.4919 - val_accuracy: 0.7886\n",
      "Epoch 532/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 533/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8024 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 534/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8004 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 535/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.8024 - val_loss: 0.4919 - val_accuracy: 0.7886\n",
      "Epoch 536/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 537/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8024 - val_loss: 0.4914 - val_accuracy: 0.7886\n",
      "Epoch 538/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8004 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 539/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7886\n",
      "Epoch 540/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8065 - val_loss: 0.4916 - val_accuracy: 0.7886\n",
      "Epoch 541/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 542/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7886\n",
      "Epoch 543/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7886\n",
      "Epoch 544/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7886\n",
      "Epoch 545/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7886\n",
      "Epoch 546/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 547/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 548/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 549/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 550/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 551/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8045 - val_loss: 0.4912 - val_accuracy: 0.7886\n",
      "Epoch 552/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8024 - val_loss: 0.4913 - val_accuracy: 0.7886\n",
      "Epoch 553/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8024 - val_loss: 0.4913 - val_accuracy: 0.7886\n",
      "Epoch 554/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8024 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 555/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 556/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 557/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 558/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 559/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 560/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 561/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
      "Epoch 562/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8045 - val_loss: 0.4923 - val_accuracy: 0.7805\n",
      "Epoch 563/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 564/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8045 - val_loss: 0.4923 - val_accuracy: 0.7805\n",
      "Epoch 565/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
      "Epoch 566/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8045 - val_loss: 0.4924 - val_accuracy: 0.7805\n",
      "Epoch 567/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
      "Epoch 568/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 569/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8045 - val_loss: 0.4921 - val_accuracy: 0.7805\n",
      "Epoch 570/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
      "Epoch 571/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 572/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 573/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 574/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 575/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 576/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 577/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 578/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 579/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 580/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 581/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 582/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 583/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 584/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 585/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 586/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 587/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 588/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 589/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 590/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8045 - val_loss: 0.4921 - val_accuracy: 0.7805\n",
      "Epoch 591/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 592/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8045 - val_loss: 0.4921 - val_accuracy: 0.7805\n",
      "Epoch 593/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 594/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 595/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 596/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 597/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 598/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 599/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 600/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 601/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 602/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8045 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 603/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 604/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 605/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 606/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 607/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
      "Epoch 608/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8045 - val_loss: 0.4921 - val_accuracy: 0.7805\n",
      "Epoch 609/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 610/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8045 - val_loss: 0.4921 - val_accuracy: 0.7805\n",
      "Epoch 611/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 612/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 613/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 614/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 615/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8045 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
      "Epoch 616/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8086 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 617/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 618/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 619/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8045 - val_loss: 0.4914 - val_accuracy: 0.7805\n",
      "Epoch 620/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 621/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8045 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 622/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 623/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8045 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 624/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8065 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 625/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8065 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 626/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8045 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 627/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8065 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 628/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8065 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 629/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8065 - val_loss: 0.4919 - val_accuracy: 0.7805\n",
      "Epoch 630/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8065 - val_loss: 0.4918 - val_accuracy: 0.7805\n",
      "Epoch 631/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8086 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 632/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8086 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 633/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8086 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 634/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8065 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
      "Epoch 635/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8086 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 636/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8086 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 637/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8086 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 638/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8086 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 639/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8086 - val_loss: 0.4912 - val_accuracy: 0.7805\n",
      "Epoch 640/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8065 - val_loss: 0.4912 - val_accuracy: 0.7805\n",
      "Epoch 641/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8086 - val_loss: 0.4911 - val_accuracy: 0.7805\n",
      "Epoch 642/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8065 - val_loss: 0.4912 - val_accuracy: 0.7805\n",
      "Epoch 643/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8086 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 644/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8086 - val_loss: 0.4914 - val_accuracy: 0.7805\n",
      "Epoch 645/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8086 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 646/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8086 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 647/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8086 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 648/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8086 - val_loss: 0.4914 - val_accuracy: 0.7805\n",
      "Epoch 649/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8086 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 650/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8086 - val_loss: 0.4916 - val_accuracy: 0.7805\n",
      "Epoch 651/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8086 - val_loss: 0.4914 - val_accuracy: 0.7805\n",
      "Epoch 652/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8106 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 653/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8106 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
      "Epoch 654/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8086 - val_loss: 0.4914 - val_accuracy: 0.7805\n",
      "Epoch 655/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8086 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
      "Epoch 656/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8065 - val_loss: 0.4910 - val_accuracy: 0.7805\n",
      "Epoch 657/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8086 - val_loss: 0.4908 - val_accuracy: 0.7805\n",
      "Epoch 658/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8086 - val_loss: 0.4910 - val_accuracy: 0.7805\n",
      "Epoch 659/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8086 - val_loss: 0.4909 - val_accuracy: 0.7805\n",
      "Epoch 660/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8106 - val_loss: 0.4907 - val_accuracy: 0.7805\n",
      "Epoch 661/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8086 - val_loss: 0.4908 - val_accuracy: 0.7805\n",
      "Epoch 662/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8086 - val_loss: 0.4907 - val_accuracy: 0.7805\n",
      "Epoch 663/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8086 - val_loss: 0.4907 - val_accuracy: 0.7805\n",
      "Epoch 664/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8106 - val_loss: 0.4906 - val_accuracy: 0.7805\n",
      "Epoch 665/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8086 - val_loss: 0.4904 - val_accuracy: 0.7805\n",
      "Epoch 666/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8086 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
      "Epoch 667/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8106 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
      "Epoch 668/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8086 - val_loss: 0.4904 - val_accuracy: 0.7805\n",
      "Epoch 669/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8086 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
      "Epoch 670/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8106 - val_loss: 0.4899 - val_accuracy: 0.7805\n",
      "Epoch 671/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7805\n",
      "Epoch 672/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7805\n",
      "Epoch 673/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8106 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 674/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 675/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8086 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 676/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8086 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 677/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8106 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 678/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 679/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 680/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8126 - val_loss: 0.4898 - val_accuracy: 0.7805\n",
      "Epoch 681/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8126 - val_loss: 0.4900 - val_accuracy: 0.7805\n",
      "Epoch 682/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8126 - val_loss: 0.4899 - val_accuracy: 0.7805\n",
      "Epoch 683/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7805\n",
      "Epoch 684/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7805\n",
      "Epoch 685/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 686/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7805\n",
      "Epoch 687/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 688/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 689/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7805\n",
      "Epoch 690/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8126 - val_loss: 0.4893 - val_accuracy: 0.7805\n",
      "Epoch 691/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8126 - val_loss: 0.4892 - val_accuracy: 0.7805\n",
      "Epoch 692/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8126 - val_loss: 0.4895 - val_accuracy: 0.7805\n",
      "Epoch 693/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8126 - val_loss: 0.4895 - val_accuracy: 0.7805\n",
      "Epoch 694/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7805\n",
      "Epoch 695/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
      "Epoch 696/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7805\n",
      "Epoch 697/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7805\n",
      "Epoch 698/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8126 - val_loss: 0.4900 - val_accuracy: 0.7724\n",
      "Epoch 699/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8126 - val_loss: 0.4900 - val_accuracy: 0.7724\n",
      "Epoch 700/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8126 - val_loss: 0.4899 - val_accuracy: 0.7724\n",
      "Epoch 701/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8106 - val_loss: 0.4899 - val_accuracy: 0.7724\n",
      "Epoch 702/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7724\n",
      "Epoch 703/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8126 - val_loss: 0.4898 - val_accuracy: 0.7724\n",
      "Epoch 704/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8126 - val_loss: 0.4899 - val_accuracy: 0.7724\n",
      "Epoch 705/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8126 - val_loss: 0.4900 - val_accuracy: 0.7724\n",
      "Epoch 706/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8126 - val_loss: 0.4901 - val_accuracy: 0.7724\n",
      "Epoch 707/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8126 - val_loss: 0.4902 - val_accuracy: 0.7805\n",
      "Epoch 708/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7724\n",
      "Epoch 709/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8126 - val_loss: 0.4895 - val_accuracy: 0.7724\n",
      "Epoch 710/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8126 - val_loss: 0.4893 - val_accuracy: 0.7724\n",
      "Epoch 711/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8126 - val_loss: 0.4892 - val_accuracy: 0.7724\n",
      "Epoch 712/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8147 - val_loss: 0.4888 - val_accuracy: 0.7805\n",
      "Epoch 713/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8126 - val_loss: 0.4887 - val_accuracy: 0.7805\n",
      "Epoch 714/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8106 - val_loss: 0.4886 - val_accuracy: 0.7805\n",
      "Epoch 715/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8106 - val_loss: 0.4886 - val_accuracy: 0.7805\n",
      "Epoch 716/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8126 - val_loss: 0.4885 - val_accuracy: 0.7805\n",
      "Epoch 717/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8126 - val_loss: 0.4887 - val_accuracy: 0.7805\n",
      "Epoch 718/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8106 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 719/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8126 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 720/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8147 - val_loss: 0.4889 - val_accuracy: 0.7886\n",
      "Epoch 721/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8147 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 722/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8126 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 723/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8147 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 724/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8147 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 725/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8147 - val_loss: 0.4887 - val_accuracy: 0.7886\n",
      "Epoch 726/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8147 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 727/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8126 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 728/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8126 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 729/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8147 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 730/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8167 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 731/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8126 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 732/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8106 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 733/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8126 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 734/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8106 - val_loss: 0.4889 - val_accuracy: 0.7886\n",
      "Epoch 735/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8126 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 736/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8106 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 737/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8106 - val_loss: 0.4887 - val_accuracy: 0.7967\n",
      "Epoch 738/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8126 - val_loss: 0.4884 - val_accuracy: 0.7886\n",
      "Epoch 739/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8106 - val_loss: 0.4887 - val_accuracy: 0.7967\n",
      "Epoch 740/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8106 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 741/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8106 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 742/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4020 - accuracy: 0.8126 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 743/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.8106 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 744/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8147 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
      "Epoch 745/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8106 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 746/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8126 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 747/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 748/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8126 - val_loss: 0.4895 - val_accuracy: 0.7886\n",
      "Epoch 749/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8126 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 750/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8147 - val_loss: 0.4895 - val_accuracy: 0.7886\n",
      "Epoch 751/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8126 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 752/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8126 - val_loss: 0.4887 - val_accuracy: 0.7886\n",
      "Epoch 753/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8126 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 754/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8147 - val_loss: 0.4889 - val_accuracy: 0.7886\n",
      "Epoch 755/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8147 - val_loss: 0.4885 - val_accuracy: 0.7886\n",
      "Epoch 756/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8126 - val_loss: 0.4887 - val_accuracy: 0.7886\n",
      "Epoch 757/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8126 - val_loss: 0.4885 - val_accuracy: 0.7886\n",
      "Epoch 758/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8167 - val_loss: 0.4882 - val_accuracy: 0.7967\n",
      "Epoch 759/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8167 - val_loss: 0.4884 - val_accuracy: 0.7886\n",
      "Epoch 760/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8167 - val_loss: 0.4885 - val_accuracy: 0.7886\n",
      "Epoch 761/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8126 - val_loss: 0.4886 - val_accuracy: 0.7886\n",
      "Epoch 762/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8126 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 763/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8167 - val_loss: 0.4889 - val_accuracy: 0.7886\n",
      "Epoch 764/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8187 - val_loss: 0.4892 - val_accuracy: 0.7967\n",
      "Epoch 765/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8187 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 766/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8187 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 767/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8167 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
      "Epoch 768/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8167 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 769/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8167 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 770/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8187 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 771/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8147 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 772/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8208 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 773/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8147 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
      "Epoch 774/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8167 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 775/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8126 - val_loss: 0.4889 - val_accuracy: 0.7886\n",
      "Epoch 776/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8167 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
      "Epoch 777/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8147 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 778/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8147 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 779/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8167 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
      "Epoch 780/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8167 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
      "Epoch 781/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8167 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
      "Epoch 782/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8187 - val_loss: 0.4898 - val_accuracy: 0.7967\n",
      "Epoch 783/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8187 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 784/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8167 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 785/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8208 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 786/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8126 - val_loss: 0.4893 - val_accuracy: 0.7967\n",
      "Epoch 787/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8208 - val_loss: 0.4892 - val_accuracy: 0.7967\n",
      "Epoch 788/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8167 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 789/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8208 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 790/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8167 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 791/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8147 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
      "Epoch 792/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8147 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
      "Epoch 793/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8208 - val_loss: 0.4898 - val_accuracy: 0.7967\n",
      "Epoch 794/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8167 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 795/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8208 - val_loss: 0.4900 - val_accuracy: 0.7886\n",
      "Epoch 796/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8147 - val_loss: 0.4901 - val_accuracy: 0.7886\n",
      "Epoch 797/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8147 - val_loss: 0.4899 - val_accuracy: 0.7886\n",
      "Epoch 798/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8147 - val_loss: 0.4897 - val_accuracy: 0.7886\n",
      "Epoch 799/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8187 - val_loss: 0.4891 - val_accuracy: 0.7805\n",
      "Epoch 800/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8106 - val_loss: 0.4888 - val_accuracy: 0.7805\n",
      "Epoch 801/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8147 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 802/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8187 - val_loss: 0.4887 - val_accuracy: 0.7805\n",
      "Epoch 803/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8167 - val_loss: 0.4889 - val_accuracy: 0.7805\n",
      "Epoch 804/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8167 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 805/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8187 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 806/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8208 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 807/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 808/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8208 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
      "Epoch 809/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8228 - val_loss: 0.4891 - val_accuracy: 0.7886\n",
      "Epoch 810/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8208 - val_loss: 0.4895 - val_accuracy: 0.7886\n",
      "Epoch 811/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8208 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
      "Epoch 812/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8187 - val_loss: 0.4897 - val_accuracy: 0.7886\n",
      "Epoch 813/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7886\n",
      "Epoch 814/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8167 - val_loss: 0.4895 - val_accuracy: 0.7886\n",
      "Epoch 815/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8187 - val_loss: 0.4900 - val_accuracy: 0.7886\n",
      "Epoch 816/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8228 - val_loss: 0.4899 - val_accuracy: 0.7886\n",
      "Epoch 817/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8208 - val_loss: 0.4901 - val_accuracy: 0.7886\n",
      "Epoch 818/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8208 - val_loss: 0.4897 - val_accuracy: 0.7886\n",
      "Epoch 819/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8208 - val_loss: 0.4900 - val_accuracy: 0.7886\n",
      "Epoch 820/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8208 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 821/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8187 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 822/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8228 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 823/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8147 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 824/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8208 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 825/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8208 - val_loss: 0.4897 - val_accuracy: 0.7886\n",
      "Epoch 826/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8228 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 827/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8167 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 828/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8167 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 829/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8147 - val_loss: 0.4901 - val_accuracy: 0.7805\n",
      "Epoch 830/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8187 - val_loss: 0.4900 - val_accuracy: 0.7805\n",
      "Epoch 831/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8147 - val_loss: 0.4900 - val_accuracy: 0.7886\n",
      "Epoch 832/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8167 - val_loss: 0.4901 - val_accuracy: 0.7886\n",
      "Epoch 833/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8228 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 834/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8187 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 835/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8208 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 836/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8208 - val_loss: 0.4905 - val_accuracy: 0.7967\n",
      "Epoch 837/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8187 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 838/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8187 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 839/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8167 - val_loss: 0.4906 - val_accuracy: 0.7967\n",
      "Epoch 840/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8228 - val_loss: 0.4901 - val_accuracy: 0.7886\n",
      "Epoch 841/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8187 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 842/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8187 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 843/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8187 - val_loss: 0.4899 - val_accuracy: 0.7886\n",
      "Epoch 844/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8187 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
      "Epoch 845/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8208 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 846/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7886\n",
      "Epoch 847/1500\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3918 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 848/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8187 - val_loss: 0.4893 - val_accuracy: 0.7967\n",
      "Epoch 849/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8187 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 850/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8187 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
      "Epoch 851/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8208 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
      "Epoch 852/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8187 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 853/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8187 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
      "Epoch 854/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8187 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 855/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8167 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 856/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8208 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 857/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 858/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 859/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8208 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 860/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8187 - val_loss: 0.4895 - val_accuracy: 0.7967\n",
      "Epoch 861/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8208 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 862/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8208 - val_loss: 0.4893 - val_accuracy: 0.7967\n",
      "Epoch 863/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8167 - val_loss: 0.4899 - val_accuracy: 0.7967\n",
      "Epoch 864/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8187 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 865/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8248 - val_loss: 0.4898 - val_accuracy: 0.7967\n",
      "Epoch 866/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8248 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 867/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8228 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 868/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8228 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 869/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8208 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 870/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8187 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
      "Epoch 871/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8228 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
      "Epoch 872/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8228 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 873/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8187 - val_loss: 0.4892 - val_accuracy: 0.7967\n",
      "Epoch 874/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8228 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
      "Epoch 875/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8248 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
      "Epoch 876/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8208 - val_loss: 0.4896 - val_accuracy: 0.7967\n",
      "Epoch 877/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8208 - val_loss: 0.4898 - val_accuracy: 0.8130\n",
      "Epoch 878/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8248 - val_loss: 0.4893 - val_accuracy: 0.7967\n",
      "Epoch 879/1500\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3887 - accuracy: 0.8228 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 880/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8208 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 881/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8228 - val_loss: 0.4889 - val_accuracy: 0.7967\n",
      "Epoch 882/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8228 - val_loss: 0.4893 - val_accuracy: 0.7967\n",
      "Epoch 883/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8248 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 884/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8228 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 885/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8228 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 886/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8228 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 887/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8248 - val_loss: 0.4889 - val_accuracy: 0.7967\n",
      "Epoch 888/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8248 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 889/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8228 - val_loss: 0.4889 - val_accuracy: 0.7967\n",
      "Epoch 890/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8248 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 891/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8228 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 892/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8228 - val_loss: 0.4892 - val_accuracy: 0.7967\n",
      "Epoch 893/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8248 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
      "Epoch 894/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8228 - val_loss: 0.4887 - val_accuracy: 0.7967\n",
      "Epoch 895/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8248 - val_loss: 0.4883 - val_accuracy: 0.7967\n",
      "Epoch 896/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8269 - val_loss: 0.4888 - val_accuracy: 0.7967\n",
      "Epoch 897/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8248 - val_loss: 0.4888 - val_accuracy: 0.7967\n",
      "Epoch 898/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8248 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
      "Epoch 899/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8248 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 900/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8248 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 901/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8228 - val_loss: 0.4892 - val_accuracy: 0.7967\n",
      "Epoch 902/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8228 - val_loss: 0.4894 - val_accuracy: 0.8049\n",
      "Epoch 903/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8269 - val_loss: 0.4894 - val_accuracy: 0.8049\n",
      "Epoch 904/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8248 - val_loss: 0.4891 - val_accuracy: 0.8049\n",
      "Epoch 905/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8228 - val_loss: 0.4892 - val_accuracy: 0.8049\n",
      "Epoch 906/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8269 - val_loss: 0.4892 - val_accuracy: 0.8049\n",
      "Epoch 907/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8248 - val_loss: 0.4896 - val_accuracy: 0.8049\n",
      "Epoch 908/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8289 - val_loss: 0.4899 - val_accuracy: 0.8049\n",
      "Epoch 909/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8248 - val_loss: 0.4902 - val_accuracy: 0.8049\n",
      "Epoch 910/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8248 - val_loss: 0.4900 - val_accuracy: 0.8049\n",
      "Epoch 911/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8269 - val_loss: 0.4902 - val_accuracy: 0.8049\n",
      "Epoch 912/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8248 - val_loss: 0.4898 - val_accuracy: 0.7967\n",
      "Epoch 913/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8248 - val_loss: 0.4899 - val_accuracy: 0.8049\n",
      "Epoch 914/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8269 - val_loss: 0.4900 - val_accuracy: 0.8049\n",
      "Epoch 915/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8269 - val_loss: 0.4900 - val_accuracy: 0.8049\n",
      "Epoch 916/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8269 - val_loss: 0.4899 - val_accuracy: 0.7967\n",
      "Epoch 917/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8248 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 918/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8248 - val_loss: 0.4893 - val_accuracy: 0.7967\n",
      "Epoch 919/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8269 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 920/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8269 - val_loss: 0.4891 - val_accuracy: 0.7967\n",
      "Epoch 921/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8289 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
      "Epoch 922/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8289 - val_loss: 0.4896 - val_accuracy: 0.7886\n",
      "Epoch 923/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8208 - val_loss: 0.4897 - val_accuracy: 0.7886\n",
      "Epoch 924/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8228 - val_loss: 0.4898 - val_accuracy: 0.7967\n",
      "Epoch 925/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 926/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8289 - val_loss: 0.4905 - val_accuracy: 0.7967\n",
      "Epoch 927/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8269 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 928/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8248 - val_loss: 0.4898 - val_accuracy: 0.7967\n",
      "Epoch 929/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8289 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 930/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8269 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 931/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.8269 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 932/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8248 - val_loss: 0.4906 - val_accuracy: 0.8049\n",
      "Epoch 933/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8269 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 934/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 935/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8289 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 936/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 937/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 938/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.7886\n",
      "Epoch 939/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8269 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 940/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8269 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 941/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.8289 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 942/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8269 - val_loss: 0.4906 - val_accuracy: 0.7967\n",
      "Epoch 943/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8269 - val_loss: 0.4905 - val_accuracy: 0.8049\n",
      "Epoch 944/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8269 - val_loss: 0.4902 - val_accuracy: 0.8049\n",
      "Epoch 945/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8289 - val_loss: 0.4905 - val_accuracy: 0.8049\n",
      "Epoch 946/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8289 - val_loss: 0.4903 - val_accuracy: 0.8049\n",
      "Epoch 947/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8289 - val_loss: 0.4903 - val_accuracy: 0.8049\n",
      "Epoch 948/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8289 - val_loss: 0.4899 - val_accuracy: 0.7967\n",
      "Epoch 949/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8310 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 950/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8289 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 951/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8289 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 952/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8289 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 953/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.8049\n",
      "Epoch 954/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.8049\n",
      "Epoch 955/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.8049\n",
      "Epoch 956/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8269 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 957/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8289 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 958/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8269 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 959/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8269 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 960/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8269 - val_loss: 0.4902 - val_accuracy: 0.8049\n",
      "Epoch 961/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8289 - val_loss: 0.4904 - val_accuracy: 0.8049\n",
      "Epoch 962/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8269 - val_loss: 0.4905 - val_accuracy: 0.7967\n",
      "Epoch 963/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8269 - val_loss: 0.4902 - val_accuracy: 0.8049\n",
      "Epoch 964/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8269 - val_loss: 0.4896 - val_accuracy: 0.8049\n",
      "Epoch 965/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8289 - val_loss: 0.4896 - val_accuracy: 0.8049\n",
      "Epoch 966/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8310 - val_loss: 0.4894 - val_accuracy: 0.8130\n",
      "Epoch 967/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8310 - val_loss: 0.4893 - val_accuracy: 0.8130\n",
      "Epoch 968/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8289 - val_loss: 0.4891 - val_accuracy: 0.8049\n",
      "Epoch 969/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8310 - val_loss: 0.4890 - val_accuracy: 0.8049\n",
      "Epoch 970/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8310 - val_loss: 0.4893 - val_accuracy: 0.8049\n",
      "Epoch 971/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8330 - val_loss: 0.4896 - val_accuracy: 0.8049\n",
      "Epoch 972/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8310 - val_loss: 0.4891 - val_accuracy: 0.8049\n",
      "Epoch 973/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8310 - val_loss: 0.4894 - val_accuracy: 0.8049\n",
      "Epoch 974/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8310 - val_loss: 0.4894 - val_accuracy: 0.8049\n",
      "Epoch 975/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8310 - val_loss: 0.4898 - val_accuracy: 0.8130\n",
      "Epoch 976/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8330 - val_loss: 0.4896 - val_accuracy: 0.8130\n",
      "Epoch 977/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8289 - val_loss: 0.4898 - val_accuracy: 0.8130\n",
      "Epoch 978/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8310 - val_loss: 0.4896 - val_accuracy: 0.8049\n",
      "Epoch 979/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8310 - val_loss: 0.4896 - val_accuracy: 0.8049\n",
      "Epoch 980/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8310 - val_loss: 0.4898 - val_accuracy: 0.8049\n",
      "Epoch 981/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8330 - val_loss: 0.4902 - val_accuracy: 0.8049\n",
      "Epoch 982/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8289 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
      "Epoch 983/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8289 - val_loss: 0.4900 - val_accuracy: 0.7967\n",
      "Epoch 984/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8310 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 985/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8310 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
      "Epoch 986/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8310 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 987/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8289 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 988/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8310 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 989/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8310 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 990/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8310 - val_loss: 0.4899 - val_accuracy: 0.7967\n",
      "Epoch 991/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8330 - val_loss: 0.4905 - val_accuracy: 0.7967\n",
      "Epoch 992/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8310 - val_loss: 0.4905 - val_accuracy: 0.7967\n",
      "Epoch 993/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8330 - val_loss: 0.4904 - val_accuracy: 0.7967\n",
      "Epoch 994/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8310 - val_loss: 0.4906 - val_accuracy: 0.7967\n",
      "Epoch 995/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8330 - val_loss: 0.4908 - val_accuracy: 0.7886\n",
      "Epoch 996/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8330 - val_loss: 0.4910 - val_accuracy: 0.7886\n",
      "Epoch 997/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8330 - val_loss: 0.4905 - val_accuracy: 0.8049\n",
      "Epoch 998/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8330 - val_loss: 0.4906 - val_accuracy: 0.7967\n",
      "Epoch 999/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8330 - val_loss: 0.4909 - val_accuracy: 0.7886\n",
      "Epoch 1000/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8330 - val_loss: 0.4911 - val_accuracy: 0.7886\n",
      "Epoch 1001/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8310 - val_loss: 0.4914 - val_accuracy: 0.7886\n",
      "Epoch 1002/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8330 - val_loss: 0.4919 - val_accuracy: 0.7967\n",
      "Epoch 1003/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8310 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 1004/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8310 - val_loss: 0.4921 - val_accuracy: 0.7886\n",
      "Epoch 1005/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8310 - val_loss: 0.4920 - val_accuracy: 0.7886\n",
      "Epoch 1006/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8330 - val_loss: 0.4923 - val_accuracy: 0.7967\n",
      "Epoch 1007/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8310 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 1008/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8310 - val_loss: 0.4930 - val_accuracy: 0.7967\n",
      "Epoch 1009/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8269 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 1010/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8310 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 1011/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8289 - val_loss: 0.4928 - val_accuracy: 0.7886\n",
      "Epoch 1012/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8330 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 1013/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8289 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
      "Epoch 1014/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8350 - val_loss: 0.4925 - val_accuracy: 0.7967\n",
      "Epoch 1015/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8310 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 1016/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8310 - val_loss: 0.4933 - val_accuracy: 0.7967\n",
      "Epoch 1017/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8330 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 1018/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8289 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 1019/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8289 - val_loss: 0.4922 - val_accuracy: 0.7967\n",
      "Epoch 1020/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8330 - val_loss: 0.4922 - val_accuracy: 0.7967\n",
      "Epoch 1021/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8350 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 1022/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8310 - val_loss: 0.4922 - val_accuracy: 0.7967\n",
      "Epoch 1023/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8330 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 1024/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8371 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 1025/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8310 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 1026/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8310 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 1027/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8330 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 1028/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8330 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 1029/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8350 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 1030/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8371 - val_loss: 0.4932 - val_accuracy: 0.7886\n",
      "Epoch 1031/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8371 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
      "Epoch 1032/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8350 - val_loss: 0.4925 - val_accuracy: 0.7967\n",
      "Epoch 1033/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8310 - val_loss: 0.4926 - val_accuracy: 0.7886\n",
      "Epoch 1034/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8330 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
      "Epoch 1035/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8330 - val_loss: 0.4926 - val_accuracy: 0.7967\n",
      "Epoch 1036/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8310 - val_loss: 0.4921 - val_accuracy: 0.7886\n",
      "Epoch 1037/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8310 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
      "Epoch 1038/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8350 - val_loss: 0.4932 - val_accuracy: 0.7967\n",
      "Epoch 1039/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8371 - val_loss: 0.4933 - val_accuracy: 0.7967\n",
      "Epoch 1040/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8330 - val_loss: 0.4934 - val_accuracy: 0.7967\n",
      "Epoch 1041/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8371 - val_loss: 0.4937 - val_accuracy: 0.7967\n",
      "Epoch 1042/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8350 - val_loss: 0.4937 - val_accuracy: 0.7967\n",
      "Epoch 1043/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8371 - val_loss: 0.4938 - val_accuracy: 0.7967\n",
      "Epoch 1044/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8371 - val_loss: 0.4940 - val_accuracy: 0.7886\n",
      "Epoch 1045/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8350 - val_loss: 0.4944 - val_accuracy: 0.7967\n",
      "Epoch 1046/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8371 - val_loss: 0.4938 - val_accuracy: 0.7886\n",
      "Epoch 1047/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8350 - val_loss: 0.4940 - val_accuracy: 0.7967\n",
      "Epoch 1048/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8350 - val_loss: 0.4940 - val_accuracy: 0.7967\n",
      "Epoch 1049/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8371 - val_loss: 0.4942 - val_accuracy: 0.7967\n",
      "Epoch 1050/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8391 - val_loss: 0.4939 - val_accuracy: 0.7967\n",
      "Epoch 1051/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8391 - val_loss: 0.4944 - val_accuracy: 0.7967\n",
      "Epoch 1052/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8371 - val_loss: 0.4943 - val_accuracy: 0.7967\n",
      "Epoch 1053/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8391 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 1054/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8411 - val_loss: 0.4945 - val_accuracy: 0.7805\n",
      "Epoch 1055/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8432 - val_loss: 0.4941 - val_accuracy: 0.7805\n",
      "Epoch 1056/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8391 - val_loss: 0.4936 - val_accuracy: 0.7967\n",
      "Epoch 1057/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8350 - val_loss: 0.4940 - val_accuracy: 0.7805\n",
      "Epoch 1058/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8391 - val_loss: 0.4941 - val_accuracy: 0.7805\n",
      "Epoch 1059/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8391 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 1060/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3684 - accuracy: 0.8411 - val_loss: 0.4949 - val_accuracy: 0.7805\n",
      "Epoch 1061/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8391 - val_loss: 0.4951 - val_accuracy: 0.7805\n",
      "Epoch 1062/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8391 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 1063/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8391 - val_loss: 0.4950 - val_accuracy: 0.7805\n",
      "Epoch 1064/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8411 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 1065/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8411 - val_loss: 0.4962 - val_accuracy: 0.7805\n",
      "Epoch 1066/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8411 - val_loss: 0.4956 - val_accuracy: 0.7805\n",
      "Epoch 1067/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8432 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 1068/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8411 - val_loss: 0.4942 - val_accuracy: 0.7886\n",
      "Epoch 1069/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8391 - val_loss: 0.4944 - val_accuracy: 0.7886\n",
      "Epoch 1070/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8371 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 1071/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8432 - val_loss: 0.4947 - val_accuracy: 0.7886\n",
      "Epoch 1072/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8391 - val_loss: 0.4941 - val_accuracy: 0.7886\n",
      "Epoch 1073/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8371 - val_loss: 0.4945 - val_accuracy: 0.7805\n",
      "Epoch 1074/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8411 - val_loss: 0.4945 - val_accuracy: 0.7805\n",
      "Epoch 1075/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8391 - val_loss: 0.4948 - val_accuracy: 0.7805\n",
      "Epoch 1076/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8411 - val_loss: 0.4950 - val_accuracy: 0.7886\n",
      "Epoch 1077/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8411 - val_loss: 0.4948 - val_accuracy: 0.7886\n",
      "Epoch 1078/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8391 - val_loss: 0.4945 - val_accuracy: 0.7886\n",
      "Epoch 1079/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8452 - val_loss: 0.4942 - val_accuracy: 0.7805\n",
      "Epoch 1080/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8391 - val_loss: 0.4946 - val_accuracy: 0.7805\n",
      "Epoch 1081/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8452 - val_loss: 0.4944 - val_accuracy: 0.7805\n",
      "Epoch 1082/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8432 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 1083/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8411 - val_loss: 0.4953 - val_accuracy: 0.7805\n",
      "Epoch 1084/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8432 - val_loss: 0.4951 - val_accuracy: 0.7805\n",
      "Epoch 1085/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8411 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 1086/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8452 - val_loss: 0.4939 - val_accuracy: 0.7805\n",
      "Epoch 1087/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8432 - val_loss: 0.4943 - val_accuracy: 0.7805\n",
      "Epoch 1088/1500\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3653 - accuracy: 0.8432 - val_loss: 0.4945 - val_accuracy: 0.7805\n",
      "Epoch 1089/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8432 - val_loss: 0.4946 - val_accuracy: 0.7805\n",
      "Epoch 1090/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8432 - val_loss: 0.4947 - val_accuracy: 0.7805\n",
      "Epoch 1091/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8432 - val_loss: 0.4951 - val_accuracy: 0.7805\n",
      "Epoch 1092/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8473 - val_loss: 0.4942 - val_accuracy: 0.7805\n",
      "Epoch 1093/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8432 - val_loss: 0.4949 - val_accuracy: 0.7805\n",
      "Epoch 1094/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8411 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 1095/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8452 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 1096/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8452 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 1097/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8452 - val_loss: 0.4953 - val_accuracy: 0.7805\n",
      "Epoch 1098/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8452 - val_loss: 0.4956 - val_accuracy: 0.7805\n",
      "Epoch 1099/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8452 - val_loss: 0.4958 - val_accuracy: 0.7805\n",
      "Epoch 1100/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8473 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 1101/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8452 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 1102/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8432 - val_loss: 0.4957 - val_accuracy: 0.7805\n",
      "Epoch 1103/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8432 - val_loss: 0.4954 - val_accuracy: 0.7805\n",
      "Epoch 1104/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8452 - val_loss: 0.4952 - val_accuracy: 0.7805\n",
      "Epoch 1105/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8452 - val_loss: 0.4961 - val_accuracy: 0.7805\n",
      "Epoch 1106/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8473 - val_loss: 0.4962 - val_accuracy: 0.7805\n",
      "Epoch 1107/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8452 - val_loss: 0.4957 - val_accuracy: 0.7805\n",
      "Epoch 1108/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8452 - val_loss: 0.4960 - val_accuracy: 0.7805\n",
      "Epoch 1109/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8432 - val_loss: 0.4963 - val_accuracy: 0.7805\n",
      "Epoch 1110/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8452 - val_loss: 0.4962 - val_accuracy: 0.7805\n",
      "Epoch 1111/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8452 - val_loss: 0.4961 - val_accuracy: 0.7805\n",
      "Epoch 1112/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8452 - val_loss: 0.4959 - val_accuracy: 0.7805\n",
      "Epoch 1113/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8452 - val_loss: 0.4957 - val_accuracy: 0.7724\n",
      "Epoch 1114/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8452 - val_loss: 0.4958 - val_accuracy: 0.7805\n",
      "Epoch 1115/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8432 - val_loss: 0.4960 - val_accuracy: 0.7805\n",
      "Epoch 1116/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8432 - val_loss: 0.4957 - val_accuracy: 0.7805\n",
      "Epoch 1117/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8432 - val_loss: 0.4960 - val_accuracy: 0.7805\n",
      "Epoch 1118/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.8432 - val_loss: 0.4963 - val_accuracy: 0.7805\n",
      "Epoch 1119/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8452 - val_loss: 0.4963 - val_accuracy: 0.7805\n",
      "Epoch 1120/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8452 - val_loss: 0.4959 - val_accuracy: 0.7805\n",
      "Epoch 1121/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8432 - val_loss: 0.4965 - val_accuracy: 0.7805\n",
      "Epoch 1122/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8452 - val_loss: 0.4962 - val_accuracy: 0.7805\n",
      "Epoch 1123/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8452 - val_loss: 0.4961 - val_accuracy: 0.7805\n",
      "Epoch 1124/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8452 - val_loss: 0.4960 - val_accuracy: 0.7805\n",
      "Epoch 1125/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8432 - val_loss: 0.4963 - val_accuracy: 0.7805\n",
      "Epoch 1126/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8432 - val_loss: 0.4964 - val_accuracy: 0.7805\n",
      "Epoch 1127/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8473 - val_loss: 0.4962 - val_accuracy: 0.7805\n",
      "Epoch 1128/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8473 - val_loss: 0.4964 - val_accuracy: 0.7805\n",
      "Epoch 1129/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8473 - val_loss: 0.4968 - val_accuracy: 0.7805\n",
      "Epoch 1130/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8452 - val_loss: 0.4963 - val_accuracy: 0.7805\n",
      "Epoch 1131/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8452 - val_loss: 0.4969 - val_accuracy: 0.7805\n",
      "Epoch 1132/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8452 - val_loss: 0.4968 - val_accuracy: 0.7805\n",
      "Epoch 1133/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8452 - val_loss: 0.4967 - val_accuracy: 0.7805\n",
      "Epoch 1134/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8411 - val_loss: 0.4965 - val_accuracy: 0.7805\n",
      "Epoch 1135/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8432 - val_loss: 0.4973 - val_accuracy: 0.7724\n",
      "Epoch 1136/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8452 - val_loss: 0.4975 - val_accuracy: 0.7724\n",
      "Epoch 1137/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.8452 - val_loss: 0.4974 - val_accuracy: 0.7724\n",
      "Epoch 1138/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8452 - val_loss: 0.4974 - val_accuracy: 0.7805\n",
      "Epoch 1139/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8452 - val_loss: 0.4974 - val_accuracy: 0.7805\n",
      "Epoch 1140/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8452 - val_loss: 0.4972 - val_accuracy: 0.7805\n",
      "Epoch 1141/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8452 - val_loss: 0.4976 - val_accuracy: 0.7805\n",
      "Epoch 1142/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8432 - val_loss: 0.4980 - val_accuracy: 0.7724\n",
      "Epoch 1143/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8432 - val_loss: 0.4978 - val_accuracy: 0.7805\n",
      "Epoch 1144/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8432 - val_loss: 0.4974 - val_accuracy: 0.7805\n",
      "Epoch 1145/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8432 - val_loss: 0.4975 - val_accuracy: 0.7724\n",
      "Epoch 1146/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8432 - val_loss: 0.4977 - val_accuracy: 0.7805\n",
      "Epoch 1147/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8452 - val_loss: 0.4978 - val_accuracy: 0.7724\n",
      "Epoch 1148/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8432 - val_loss: 0.4981 - val_accuracy: 0.7724\n",
      "Epoch 1149/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8452 - val_loss: 0.4985 - val_accuracy: 0.7724\n",
      "Epoch 1150/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8432 - val_loss: 0.4985 - val_accuracy: 0.7724\n",
      "Epoch 1151/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8411 - val_loss: 0.4975 - val_accuracy: 0.7805\n",
      "Epoch 1152/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8411 - val_loss: 0.4981 - val_accuracy: 0.7805\n",
      "Epoch 1153/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8432 - val_loss: 0.4981 - val_accuracy: 0.7805\n",
      "Epoch 1154/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8411 - val_loss: 0.4982 - val_accuracy: 0.7805\n",
      "Epoch 1155/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8452 - val_loss: 0.4985 - val_accuracy: 0.7724\n",
      "Epoch 1156/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8452 - val_loss: 0.4980 - val_accuracy: 0.7724\n",
      "Epoch 1157/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8411 - val_loss: 0.4978 - val_accuracy: 0.7805\n",
      "Epoch 1158/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8432 - val_loss: 0.4984 - val_accuracy: 0.7724\n",
      "Epoch 1159/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8432 - val_loss: 0.4987 - val_accuracy: 0.7724\n",
      "Epoch 1160/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8452 - val_loss: 0.4989 - val_accuracy: 0.7724\n",
      "Epoch 1161/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8411 - val_loss: 0.4992 - val_accuracy: 0.7724\n",
      "Epoch 1162/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8432 - val_loss: 0.4991 - val_accuracy: 0.7724\n",
      "Epoch 1163/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8432 - val_loss: 0.4992 - val_accuracy: 0.7886\n",
      "Epoch 1164/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8432 - val_loss: 0.4991 - val_accuracy: 0.7724\n",
      "Epoch 1165/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8411 - val_loss: 0.4996 - val_accuracy: 0.7724\n",
      "Epoch 1166/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8411 - val_loss: 0.4994 - val_accuracy: 0.7724\n",
      "Epoch 1167/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8432 - val_loss: 0.4999 - val_accuracy: 0.7724\n",
      "Epoch 1168/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8411 - val_loss: 0.5000 - val_accuracy: 0.7724\n",
      "Epoch 1169/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8452 - val_loss: 0.4999 - val_accuracy: 0.7724\n",
      "Epoch 1170/1500\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3565 - accuracy: 0.8432 - val_loss: 0.5001 - val_accuracy: 0.7724\n",
      "Epoch 1171/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8432 - val_loss: 0.5003 - val_accuracy: 0.7724\n",
      "Epoch 1172/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8411 - val_loss: 0.5003 - val_accuracy: 0.7724\n",
      "Epoch 1173/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8432 - val_loss: 0.5001 - val_accuracy: 0.7724\n",
      "Epoch 1174/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8432 - val_loss: 0.5001 - val_accuracy: 0.7724\n",
      "Epoch 1175/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3561 - accuracy: 0.8411 - val_loss: 0.5007 - val_accuracy: 0.7724\n",
      "Epoch 1176/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8432 - val_loss: 0.5009 - val_accuracy: 0.7724\n",
      "Epoch 1177/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8432 - val_loss: 0.5004 - val_accuracy: 0.7724\n",
      "Epoch 1178/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8452 - val_loss: 0.4999 - val_accuracy: 0.7805\n",
      "Epoch 1179/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8473 - val_loss: 0.5009 - val_accuracy: 0.7724\n",
      "Epoch 1180/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8473 - val_loss: 0.5016 - val_accuracy: 0.7724\n",
      "Epoch 1181/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8473 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
      "Epoch 1182/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8432 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
      "Epoch 1183/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8452 - val_loss: 0.5022 - val_accuracy: 0.7724\n",
      "Epoch 1184/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8432 - val_loss: 0.5021 - val_accuracy: 0.7724\n",
      "Epoch 1185/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8452 - val_loss: 0.5026 - val_accuracy: 0.7724\n",
      "Epoch 1186/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8473 - val_loss: 0.5022 - val_accuracy: 0.7724\n",
      "Epoch 1187/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8473 - val_loss: 0.5024 - val_accuracy: 0.7724\n",
      "Epoch 1188/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8493 - val_loss: 0.5029 - val_accuracy: 0.7724\n",
      "Epoch 1189/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8473 - val_loss: 0.5030 - val_accuracy: 0.7724\n",
      "Epoch 1190/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8473 - val_loss: 0.5029 - val_accuracy: 0.7724\n",
      "Epoch 1191/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8493 - val_loss: 0.5028 - val_accuracy: 0.7724\n",
      "Epoch 1192/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8473 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
      "Epoch 1193/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8493 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
      "Epoch 1194/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8452 - val_loss: 0.5037 - val_accuracy: 0.7724\n",
      "Epoch 1195/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8473 - val_loss: 0.5039 - val_accuracy: 0.7724\n",
      "Epoch 1196/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8513 - val_loss: 0.5037 - val_accuracy: 0.7724\n",
      "Epoch 1197/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8473 - val_loss: 0.5034 - val_accuracy: 0.7724\n",
      "Epoch 1198/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8473 - val_loss: 0.5033 - val_accuracy: 0.7724\n",
      "Epoch 1199/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8452 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
      "Epoch 1200/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8493 - val_loss: 0.5034 - val_accuracy: 0.7724\n",
      "Epoch 1201/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.5035 - val_accuracy: 0.7724\n",
      "Epoch 1202/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8473 - val_loss: 0.5032 - val_accuracy: 0.7724\n",
      "Epoch 1203/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.5035 - val_accuracy: 0.7724\n",
      "Epoch 1204/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8493 - val_loss: 0.5032 - val_accuracy: 0.7805\n",
      "Epoch 1205/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8473 - val_loss: 0.5034 - val_accuracy: 0.7724\n",
      "Epoch 1206/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8493 - val_loss: 0.5038 - val_accuracy: 0.7724\n",
      "Epoch 1207/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8493 - val_loss: 0.5043 - val_accuracy: 0.7724\n",
      "Epoch 1208/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8493 - val_loss: 0.5045 - val_accuracy: 0.7642\n",
      "Epoch 1209/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8493 - val_loss: 0.5041 - val_accuracy: 0.7724\n",
      "Epoch 1210/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8493 - val_loss: 0.5047 - val_accuracy: 0.7724\n",
      "Epoch 1211/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8513 - val_loss: 0.5054 - val_accuracy: 0.7724\n",
      "Epoch 1212/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8493 - val_loss: 0.5056 - val_accuracy: 0.7724\n",
      "Epoch 1213/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8473 - val_loss: 0.5062 - val_accuracy: 0.7724\n",
      "Epoch 1214/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.5065 - val_accuracy: 0.7724\n",
      "Epoch 1215/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8534 - val_loss: 0.5063 - val_accuracy: 0.7724\n",
      "Epoch 1216/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8493 - val_loss: 0.5061 - val_accuracy: 0.7724\n",
      "Epoch 1217/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8493 - val_loss: 0.5071 - val_accuracy: 0.7724\n",
      "Epoch 1218/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8493 - val_loss: 0.5071 - val_accuracy: 0.7724\n",
      "Epoch 1219/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8513 - val_loss: 0.5072 - val_accuracy: 0.7642\n",
      "Epoch 1220/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8534 - val_loss: 0.5072 - val_accuracy: 0.7642\n",
      "Epoch 1221/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3508 - accuracy: 0.8513 - val_loss: 0.5072 - val_accuracy: 0.7642\n",
      "Epoch 1222/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8513 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
      "Epoch 1223/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8513 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
      "Epoch 1224/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8554 - val_loss: 0.5075 - val_accuracy: 0.7642\n",
      "Epoch 1225/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8493 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
      "Epoch 1226/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8534 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
      "Epoch 1227/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8534 - val_loss: 0.5089 - val_accuracy: 0.7642\n",
      "Epoch 1228/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8554 - val_loss: 0.5092 - val_accuracy: 0.7642\n",
      "Epoch 1229/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8513 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
      "Epoch 1230/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8554 - val_loss: 0.5091 - val_accuracy: 0.7642\n",
      "Epoch 1231/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8554 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
      "Epoch 1232/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8534 - val_loss: 0.5109 - val_accuracy: 0.7642\n",
      "Epoch 1233/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8554 - val_loss: 0.5104 - val_accuracy: 0.7642\n",
      "Epoch 1234/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8554 - val_loss: 0.5100 - val_accuracy: 0.7642\n",
      "Epoch 1235/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8534 - val_loss: 0.5105 - val_accuracy: 0.7642\n",
      "Epoch 1236/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8534 - val_loss: 0.5103 - val_accuracy: 0.7642\n",
      "Epoch 1237/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8534 - val_loss: 0.5107 - val_accuracy: 0.7642\n",
      "Epoch 1238/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8554 - val_loss: 0.5108 - val_accuracy: 0.7642\n",
      "Epoch 1239/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8554 - val_loss: 0.5108 - val_accuracy: 0.7642\n",
      "Epoch 1240/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8554 - val_loss: 0.5112 - val_accuracy: 0.7642\n",
      "Epoch 1241/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8574 - val_loss: 0.5118 - val_accuracy: 0.7642\n",
      "Epoch 1242/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8574 - val_loss: 0.5109 - val_accuracy: 0.7642\n",
      "Epoch 1243/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8554 - val_loss: 0.5112 - val_accuracy: 0.7561\n",
      "Epoch 1244/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3482 - accuracy: 0.8534 - val_loss: 0.5116 - val_accuracy: 0.7642\n",
      "Epoch 1245/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8554 - val_loss: 0.5113 - val_accuracy: 0.7642\n",
      "Epoch 1246/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8554 - val_loss: 0.5116 - val_accuracy: 0.7642\n",
      "Epoch 1247/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8574 - val_loss: 0.5124 - val_accuracy: 0.7642\n",
      "Epoch 1248/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8574 - val_loss: 0.5131 - val_accuracy: 0.7642\n",
      "Epoch 1249/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8574 - val_loss: 0.5125 - val_accuracy: 0.7642\n",
      "Epoch 1250/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8574 - val_loss: 0.5127 - val_accuracy: 0.7642\n",
      "Epoch 1251/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8554 - val_loss: 0.5134 - val_accuracy: 0.7642\n",
      "Epoch 1252/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8574 - val_loss: 0.5140 - val_accuracy: 0.7642\n",
      "Epoch 1253/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8595 - val_loss: 0.5135 - val_accuracy: 0.7642\n",
      "Epoch 1254/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8574 - val_loss: 0.5135 - val_accuracy: 0.7561\n",
      "Epoch 1255/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8595 - val_loss: 0.5137 - val_accuracy: 0.7561\n",
      "Epoch 1256/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8595 - val_loss: 0.5126 - val_accuracy: 0.7561\n",
      "Epoch 1257/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8595 - val_loss: 0.5132 - val_accuracy: 0.7642\n",
      "Epoch 1258/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8574 - val_loss: 0.5133 - val_accuracy: 0.7642\n",
      "Epoch 1259/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8574 - val_loss: 0.5137 - val_accuracy: 0.7561\n",
      "Epoch 1260/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8635 - val_loss: 0.5127 - val_accuracy: 0.7561\n",
      "Epoch 1261/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8615 - val_loss: 0.5129 - val_accuracy: 0.7561\n",
      "Epoch 1262/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3465 - accuracy: 0.8595 - val_loss: 0.5136 - val_accuracy: 0.7561\n",
      "Epoch 1263/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8554 - val_loss: 0.5133 - val_accuracy: 0.7561\n",
      "Epoch 1264/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8554 - val_loss: 0.5135 - val_accuracy: 0.7561\n",
      "Epoch 1265/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8574 - val_loss: 0.5130 - val_accuracy: 0.7561\n",
      "Epoch 1266/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8595 - val_loss: 0.5142 - val_accuracy: 0.7561\n",
      "Epoch 1267/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8554 - val_loss: 0.5135 - val_accuracy: 0.7561\n",
      "Epoch 1268/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3461 - accuracy: 0.8554 - val_loss: 0.5137 - val_accuracy: 0.7561\n",
      "Epoch 1269/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3460 - accuracy: 0.8554 - val_loss: 0.5149 - val_accuracy: 0.7561\n",
      "Epoch 1270/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3460 - accuracy: 0.8595 - val_loss: 0.5146 - val_accuracy: 0.7561\n",
      "Epoch 1271/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8615 - val_loss: 0.5141 - val_accuracy: 0.7561\n",
      "Epoch 1272/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8554 - val_loss: 0.5140 - val_accuracy: 0.7561\n",
      "Epoch 1273/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8534 - val_loss: 0.5143 - val_accuracy: 0.7561\n",
      "Epoch 1274/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8554 - val_loss: 0.5147 - val_accuracy: 0.7561\n",
      "Epoch 1275/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8554 - val_loss: 0.5157 - val_accuracy: 0.7642\n",
      "Epoch 1276/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8595 - val_loss: 0.5155 - val_accuracy: 0.7642\n",
      "Epoch 1277/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3451 - accuracy: 0.8595 - val_loss: 0.5155 - val_accuracy: 0.7642\n",
      "Epoch 1278/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8574 - val_loss: 0.5148 - val_accuracy: 0.7642\n",
      "Epoch 1279/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8574 - val_loss: 0.5156 - val_accuracy: 0.7642\n",
      "Epoch 1280/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8595 - val_loss: 0.5150 - val_accuracy: 0.7642\n",
      "Epoch 1281/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8574 - val_loss: 0.5162 - val_accuracy: 0.7561\n",
      "Epoch 1282/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8574 - val_loss: 0.5167 - val_accuracy: 0.7561\n",
      "Epoch 1283/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8595 - val_loss: 0.5160 - val_accuracy: 0.7561\n",
      "Epoch 1284/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8595 - val_loss: 0.5155 - val_accuracy: 0.7642\n",
      "Epoch 1285/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8595 - val_loss: 0.5160 - val_accuracy: 0.7642\n",
      "Epoch 1286/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8615 - val_loss: 0.5167 - val_accuracy: 0.7642\n",
      "Epoch 1287/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8595 - val_loss: 0.5170 - val_accuracy: 0.7642\n",
      "Epoch 1288/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8615 - val_loss: 0.5170 - val_accuracy: 0.7561\n",
      "Epoch 1289/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8595 - val_loss: 0.5171 - val_accuracy: 0.7642\n",
      "Epoch 1290/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8615 - val_loss: 0.5175 - val_accuracy: 0.7561\n",
      "Epoch 1291/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8574 - val_loss: 0.5175 - val_accuracy: 0.7561\n",
      "Epoch 1292/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8574 - val_loss: 0.5182 - val_accuracy: 0.7561\n",
      "Epoch 1293/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8595 - val_loss: 0.5182 - val_accuracy: 0.7642\n",
      "Epoch 1294/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8574 - val_loss: 0.5169 - val_accuracy: 0.7642\n",
      "Epoch 1295/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8615 - val_loss: 0.5165 - val_accuracy: 0.7642\n",
      "Epoch 1296/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.8615 - val_loss: 0.5167 - val_accuracy: 0.7561\n",
      "Epoch 1297/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3429 - accuracy: 0.8574 - val_loss: 0.5167 - val_accuracy: 0.7642\n",
      "Epoch 1298/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3427 - accuracy: 0.8574 - val_loss: 0.5171 - val_accuracy: 0.7642\n",
      "Epoch 1299/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8574 - val_loss: 0.5171 - val_accuracy: 0.7561\n",
      "Epoch 1300/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8574 - val_loss: 0.5162 - val_accuracy: 0.7642\n",
      "Epoch 1301/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8554 - val_loss: 0.5164 - val_accuracy: 0.7561\n",
      "Epoch 1302/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8574 - val_loss: 0.5164 - val_accuracy: 0.7642\n",
      "Epoch 1303/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8554 - val_loss: 0.5170 - val_accuracy: 0.7642\n",
      "Epoch 1304/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8574 - val_loss: 0.5167 - val_accuracy: 0.7642\n",
      "Epoch 1305/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8554 - val_loss: 0.5177 - val_accuracy: 0.7642\n",
      "Epoch 1306/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8574 - val_loss: 0.5186 - val_accuracy: 0.7561\n",
      "Epoch 1307/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8554 - val_loss: 0.5184 - val_accuracy: 0.7561\n",
      "Epoch 1308/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8595 - val_loss: 0.5185 - val_accuracy: 0.7642\n",
      "Epoch 1309/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8554 - val_loss: 0.5190 - val_accuracy: 0.7561\n",
      "Epoch 1310/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8635 - val_loss: 0.5192 - val_accuracy: 0.7642\n",
      "Epoch 1311/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8595 - val_loss: 0.5183 - val_accuracy: 0.7642\n",
      "Epoch 1312/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8574 - val_loss: 0.5183 - val_accuracy: 0.7642\n",
      "Epoch 1313/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8615 - val_loss: 0.5178 - val_accuracy: 0.7642\n",
      "Epoch 1314/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8595 - val_loss: 0.5186 - val_accuracy: 0.7642\n",
      "Epoch 1315/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8554 - val_loss: 0.5187 - val_accuracy: 0.7561\n",
      "Epoch 1316/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3409 - accuracy: 0.8554 - val_loss: 0.5184 - val_accuracy: 0.7642\n",
      "Epoch 1317/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8574 - val_loss: 0.5198 - val_accuracy: 0.7561\n",
      "Epoch 1318/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8595 - val_loss: 0.5190 - val_accuracy: 0.7642\n",
      "Epoch 1319/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8656 - val_loss: 0.5199 - val_accuracy: 0.7561\n",
      "Epoch 1320/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.8595 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 1321/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.8595 - val_loss: 0.5202 - val_accuracy: 0.7480\n",
      "Epoch 1322/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3401 - accuracy: 0.8574 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
      "Epoch 1323/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3402 - accuracy: 0.8615 - val_loss: 0.5207 - val_accuracy: 0.7561\n",
      "Epoch 1324/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8656 - val_loss: 0.5208 - val_accuracy: 0.7561\n",
      "Epoch 1325/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8615 - val_loss: 0.5209 - val_accuracy: 0.7561\n",
      "Epoch 1326/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8635 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
      "Epoch 1327/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8615 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
      "Epoch 1328/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8615 - val_loss: 0.5222 - val_accuracy: 0.7561\n",
      "Epoch 1329/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8615 - val_loss: 0.5221 - val_accuracy: 0.7480\n",
      "Epoch 1330/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8615 - val_loss: 0.5224 - val_accuracy: 0.7480\n",
      "Epoch 1331/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8595 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
      "Epoch 1332/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3391 - accuracy: 0.8615 - val_loss: 0.5221 - val_accuracy: 0.7480\n",
      "Epoch 1333/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8595 - val_loss: 0.5225 - val_accuracy: 0.7561\n",
      "Epoch 1334/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8615 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
      "Epoch 1335/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8615 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
      "Epoch 1336/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8595 - val_loss: 0.5231 - val_accuracy: 0.7480\n",
      "Epoch 1337/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8574 - val_loss: 0.5237 - val_accuracy: 0.7480\n",
      "Epoch 1338/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8595 - val_loss: 0.5234 - val_accuracy: 0.7480\n",
      "Epoch 1339/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8615 - val_loss: 0.5229 - val_accuracy: 0.7480\n",
      "Epoch 1340/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8595 - val_loss: 0.5227 - val_accuracy: 0.7480\n",
      "Epoch 1341/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8615 - val_loss: 0.5234 - val_accuracy: 0.7480\n",
      "Epoch 1342/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8595 - val_loss: 0.5234 - val_accuracy: 0.7480\n",
      "Epoch 1343/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8615 - val_loss: 0.5245 - val_accuracy: 0.7398\n",
      "Epoch 1344/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8656 - val_loss: 0.5243 - val_accuracy: 0.7480\n",
      "Epoch 1345/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.8595 - val_loss: 0.5239 - val_accuracy: 0.7480\n",
      "Epoch 1346/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8615 - val_loss: 0.5241 - val_accuracy: 0.7480\n",
      "Epoch 1347/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8635 - val_loss: 0.5233 - val_accuracy: 0.7561\n",
      "Epoch 1348/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8635 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
      "Epoch 1349/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8615 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
      "Epoch 1350/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8656 - val_loss: 0.5243 - val_accuracy: 0.7480\n",
      "Epoch 1351/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8615 - val_loss: 0.5239 - val_accuracy: 0.7561\n",
      "Epoch 1352/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8615 - val_loss: 0.5239 - val_accuracy: 0.7561\n",
      "Epoch 1353/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8635 - val_loss: 0.5243 - val_accuracy: 0.7561\n",
      "Epoch 1354/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8635 - val_loss: 0.5237 - val_accuracy: 0.7561\n",
      "Epoch 1355/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8595 - val_loss: 0.5249 - val_accuracy: 0.7480\n",
      "Epoch 1356/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8615 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
      "Epoch 1357/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8656 - val_loss: 0.5239 - val_accuracy: 0.7561\n",
      "Epoch 1358/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8656 - val_loss: 0.5242 - val_accuracy: 0.7561\n",
      "Epoch 1359/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8656 - val_loss: 0.5244 - val_accuracy: 0.7480\n",
      "Epoch 1360/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8656 - val_loss: 0.5237 - val_accuracy: 0.7561\n",
      "Epoch 1361/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3360 - accuracy: 0.8676 - val_loss: 0.5249 - val_accuracy: 0.7480\n",
      "Epoch 1362/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8656 - val_loss: 0.5255 - val_accuracy: 0.7480\n",
      "Epoch 1363/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8635 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
      "Epoch 1364/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8656 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
      "Epoch 1365/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8635 - val_loss: 0.5247 - val_accuracy: 0.7398\n",
      "Epoch 1366/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3354 - accuracy: 0.8635 - val_loss: 0.5250 - val_accuracy: 0.7398\n",
      "Epoch 1367/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8656 - val_loss: 0.5253 - val_accuracy: 0.7398\n",
      "Epoch 1368/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8615 - val_loss: 0.5249 - val_accuracy: 0.7480\n",
      "Epoch 1369/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.8615 - val_loss: 0.5254 - val_accuracy: 0.7398\n",
      "Epoch 1370/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8635 - val_loss: 0.5261 - val_accuracy: 0.7398\n",
      "Epoch 1371/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8635 - val_loss: 0.5250 - val_accuracy: 0.7480\n",
      "Epoch 1372/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8656 - val_loss: 0.5259 - val_accuracy: 0.7398\n",
      "Epoch 1373/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.5260 - val_accuracy: 0.7398\n",
      "Epoch 1374/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.5260 - val_accuracy: 0.7398\n",
      "Epoch 1375/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.5259 - val_accuracy: 0.7398\n",
      "Epoch 1376/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8635 - val_loss: 0.5271 - val_accuracy: 0.7398\n",
      "Epoch 1377/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8656 - val_loss: 0.5269 - val_accuracy: 0.7398\n",
      "Epoch 1378/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8635 - val_loss: 0.5269 - val_accuracy: 0.7398\n",
      "Epoch 1379/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8656 - val_loss: 0.5270 - val_accuracy: 0.7480\n",
      "Epoch 1380/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8595 - val_loss: 0.5266 - val_accuracy: 0.7480\n",
      "Epoch 1381/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8635 - val_loss: 0.5282 - val_accuracy: 0.7398\n",
      "Epoch 1382/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8656 - val_loss: 0.5268 - val_accuracy: 0.7480\n",
      "Epoch 1383/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8676 - val_loss: 0.5272 - val_accuracy: 0.7480\n",
      "Epoch 1384/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8676 - val_loss: 0.5270 - val_accuracy: 0.7480\n",
      "Epoch 1385/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8676 - val_loss: 0.5265 - val_accuracy: 0.7480\n",
      "Epoch 1386/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8635 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
      "Epoch 1387/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8656 - val_loss: 0.5260 - val_accuracy: 0.7480\n",
      "Epoch 1388/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8656 - val_loss: 0.5261 - val_accuracy: 0.7480\n",
      "Epoch 1389/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8656 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
      "Epoch 1390/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8656 - val_loss: 0.5268 - val_accuracy: 0.7480\n",
      "Epoch 1391/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8697 - val_loss: 0.5267 - val_accuracy: 0.7480\n",
      "Epoch 1392/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.8635 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
      "Epoch 1393/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8656 - val_loss: 0.5267 - val_accuracy: 0.7480\n",
      "Epoch 1394/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8676 - val_loss: 0.5266 - val_accuracy: 0.7480\n",
      "Epoch 1395/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8676 - val_loss: 0.5272 - val_accuracy: 0.7480\n",
      "Epoch 1396/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8656 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
      "Epoch 1397/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8615 - val_loss: 0.5272 - val_accuracy: 0.7480\n",
      "Epoch 1398/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8676 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
      "Epoch 1399/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8656 - val_loss: 0.5275 - val_accuracy: 0.7480\n",
      "Epoch 1400/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8656 - val_loss: 0.5272 - val_accuracy: 0.7480\n",
      "Epoch 1401/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8656 - val_loss: 0.5279 - val_accuracy: 0.7480\n",
      "Epoch 1402/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8635 - val_loss: 0.5288 - val_accuracy: 0.7480\n",
      "Epoch 1403/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8676 - val_loss: 0.5282 - val_accuracy: 0.7480\n",
      "Epoch 1404/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8676 - val_loss: 0.5283 - val_accuracy: 0.7480\n",
      "Epoch 1405/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8615 - val_loss: 0.5289 - val_accuracy: 0.7480\n",
      "Epoch 1406/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8615 - val_loss: 0.5295 - val_accuracy: 0.7480\n",
      "Epoch 1407/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8656 - val_loss: 0.5290 - val_accuracy: 0.7480\n",
      "Epoch 1408/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8697 - val_loss: 0.5290 - val_accuracy: 0.7480\n",
      "Epoch 1409/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8676 - val_loss: 0.5290 - val_accuracy: 0.7480\n",
      "Epoch 1410/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8676 - val_loss: 0.5301 - val_accuracy: 0.7480\n",
      "Epoch 1411/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8635 - val_loss: 0.5315 - val_accuracy: 0.7398\n",
      "Epoch 1412/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8697 - val_loss: 0.5309 - val_accuracy: 0.7398\n",
      "Epoch 1413/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8697 - val_loss: 0.5303 - val_accuracy: 0.7480\n",
      "Epoch 1414/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8656 - val_loss: 0.5314 - val_accuracy: 0.7398\n",
      "Epoch 1415/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.8635 - val_loss: 0.5317 - val_accuracy: 0.7480\n",
      "Epoch 1416/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8697 - val_loss: 0.5309 - val_accuracy: 0.7480\n",
      "Epoch 1417/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8676 - val_loss: 0.5301 - val_accuracy: 0.7480\n",
      "Epoch 1418/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8676 - val_loss: 0.5316 - val_accuracy: 0.7480\n",
      "Epoch 1419/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8656 - val_loss: 0.5322 - val_accuracy: 0.7480\n",
      "Epoch 1420/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8656 - val_loss: 0.5306 - val_accuracy: 0.7480\n",
      "Epoch 1421/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8676 - val_loss: 0.5306 - val_accuracy: 0.7480\n",
      "Epoch 1422/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8656 - val_loss: 0.5322 - val_accuracy: 0.7480\n",
      "Epoch 1423/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8676 - val_loss: 0.5319 - val_accuracy: 0.7480\n",
      "Epoch 1424/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8697 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 1425/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8676 - val_loss: 0.5331 - val_accuracy: 0.7398\n",
      "Epoch 1426/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8717 - val_loss: 0.5321 - val_accuracy: 0.7480\n",
      "Epoch 1427/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8737 - val_loss: 0.5321 - val_accuracy: 0.7480\n",
      "Epoch 1428/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8697 - val_loss: 0.5318 - val_accuracy: 0.7480\n",
      "Epoch 1429/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8676 - val_loss: 0.5336 - val_accuracy: 0.7398\n",
      "Epoch 1430/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8656 - val_loss: 0.5341 - val_accuracy: 0.7398\n",
      "Epoch 1431/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8697 - val_loss: 0.5338 - val_accuracy: 0.7480\n",
      "Epoch 1432/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8737 - val_loss: 0.5341 - val_accuracy: 0.7480\n",
      "Epoch 1433/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8717 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
      "Epoch 1434/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8697 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 1435/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8635 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
      "Epoch 1436/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8697 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
      "Epoch 1437/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8676 - val_loss: 0.5340 - val_accuracy: 0.7480\n",
      "Epoch 1438/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8656 - val_loss: 0.5332 - val_accuracy: 0.7480\n",
      "Epoch 1439/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8676 - val_loss: 0.5340 - val_accuracy: 0.7480\n",
      "Epoch 1440/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8758 - val_loss: 0.5345 - val_accuracy: 0.7480\n",
      "Epoch 1441/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8697 - val_loss: 0.5327 - val_accuracy: 0.7480\n",
      "Epoch 1442/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8697 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 1443/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8697 - val_loss: 0.5327 - val_accuracy: 0.7480\n",
      "Epoch 1444/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8656 - val_loss: 0.5328 - val_accuracy: 0.7480\n",
      "Epoch 1445/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8676 - val_loss: 0.5327 - val_accuracy: 0.7480\n",
      "Epoch 1446/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8635 - val_loss: 0.5329 - val_accuracy: 0.7480\n",
      "Epoch 1447/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8676 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 1448/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8615 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
      "Epoch 1449/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8656 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 1450/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8676 - val_loss: 0.5330 - val_accuracy: 0.7480\n",
      "Epoch 1451/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3257 - accuracy: 0.8656 - val_loss: 0.5347 - val_accuracy: 0.7480\n",
      "Epoch 1452/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8676 - val_loss: 0.5349 - val_accuracy: 0.7480\n",
      "Epoch 1453/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.8635 - val_loss: 0.5359 - val_accuracy: 0.7480\n",
      "Epoch 1454/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8717 - val_loss: 0.5363 - val_accuracy: 0.7480\n",
      "Epoch 1455/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8737 - val_loss: 0.5363 - val_accuracy: 0.7480\n",
      "Epoch 1456/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8656 - val_loss: 0.5357 - val_accuracy: 0.7480\n",
      "Epoch 1457/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8676 - val_loss: 0.5357 - val_accuracy: 0.7480\n",
      "Epoch 1458/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8676 - val_loss: 0.5360 - val_accuracy: 0.7480\n",
      "Epoch 1459/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8717 - val_loss: 0.5370 - val_accuracy: 0.7480\n",
      "Epoch 1460/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8697 - val_loss: 0.5356 - val_accuracy: 0.7480\n",
      "Epoch 1461/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3246 - accuracy: 0.8676 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 1462/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3245 - accuracy: 0.8676 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 1463/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3246 - accuracy: 0.8656 - val_loss: 0.5345 - val_accuracy: 0.7480\n",
      "Epoch 1464/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8697 - val_loss: 0.5344 - val_accuracy: 0.7480\n",
      "Epoch 1465/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3241 - accuracy: 0.8697 - val_loss: 0.5343 - val_accuracy: 0.7480\n",
      "Epoch 1466/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8676 - val_loss: 0.5350 - val_accuracy: 0.7480\n",
      "Epoch 1467/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.8656 - val_loss: 0.5363 - val_accuracy: 0.7480\n",
      "Epoch 1468/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8717 - val_loss: 0.5360 - val_accuracy: 0.7480\n",
      "Epoch 1469/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8656 - val_loss: 0.5359 - val_accuracy: 0.7480\n",
      "Epoch 1470/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.8676 - val_loss: 0.5367 - val_accuracy: 0.7480\n",
      "Epoch 1471/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.8697 - val_loss: 0.5371 - val_accuracy: 0.7480\n",
      "Epoch 1472/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8717 - val_loss: 0.5382 - val_accuracy: 0.7480\n",
      "Epoch 1473/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8676 - val_loss: 0.5382 - val_accuracy: 0.7480\n",
      "Epoch 1474/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3233 - accuracy: 0.8697 - val_loss: 0.5364 - val_accuracy: 0.7480\n",
      "Epoch 1475/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8697 - val_loss: 0.5357 - val_accuracy: 0.7480\n",
      "Epoch 1476/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8717 - val_loss: 0.5357 - val_accuracy: 0.7480\n",
      "Epoch 1477/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.8697 - val_loss: 0.5355 - val_accuracy: 0.7480\n",
      "Epoch 1478/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3226 - accuracy: 0.8717 - val_loss: 0.5375 - val_accuracy: 0.7480\n",
      "Epoch 1479/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8737 - val_loss: 0.5362 - val_accuracy: 0.7480\n",
      "Epoch 1480/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8697 - val_loss: 0.5372 - val_accuracy: 0.7480\n",
      "Epoch 1481/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8697 - val_loss: 0.5373 - val_accuracy: 0.7480\n",
      "Epoch 1482/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.8717 - val_loss: 0.5370 - val_accuracy: 0.7480\n",
      "Epoch 1483/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3221 - accuracy: 0.8697 - val_loss: 0.5376 - val_accuracy: 0.7480\n",
      "Epoch 1484/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3221 - accuracy: 0.8737 - val_loss: 0.5379 - val_accuracy: 0.7480\n",
      "Epoch 1485/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3219 - accuracy: 0.8717 - val_loss: 0.5389 - val_accuracy: 0.7480\n",
      "Epoch 1486/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3220 - accuracy: 0.8717 - val_loss: 0.5388 - val_accuracy: 0.7480\n",
      "Epoch 1487/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3220 - accuracy: 0.8717 - val_loss: 0.5383 - val_accuracy: 0.7480\n",
      "Epoch 1488/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8697 - val_loss: 0.5391 - val_accuracy: 0.7480\n",
      "Epoch 1489/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8737 - val_loss: 0.5396 - val_accuracy: 0.7480\n",
      "Epoch 1490/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3217 - accuracy: 0.8717 - val_loss: 0.5387 - val_accuracy: 0.7480\n",
      "Epoch 1491/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8778 - val_loss: 0.5390 - val_accuracy: 0.7480\n",
      "Epoch 1492/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8758 - val_loss: 0.5389 - val_accuracy: 0.7480\n",
      "Epoch 1493/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3213 - accuracy: 0.8717 - val_loss: 0.5380 - val_accuracy: 0.7480\n",
      "Epoch 1494/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8717 - val_loss: 0.5392 - val_accuracy: 0.7480\n",
      "Epoch 1495/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8737 - val_loss: 0.5384 - val_accuracy: 0.7480\n",
      "Epoch 1496/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8717 - val_loss: 0.5383 - val_accuracy: 0.7480\n",
      "Epoch 1497/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3209 - accuracy: 0.8758 - val_loss: 0.5376 - val_accuracy: 0.7480\n",
      "Epoch 1498/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8717 - val_loss: 0.5377 - val_accuracy: 0.7480\n",
      "Epoch 1499/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8717 - val_loss: 0.5389 - val_accuracy: 0.7480\n",
      "Epoch 1500/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3204 - accuracy: 0.8758 - val_loss: 0.5391 - val_accuracy: 0.7480\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "accuracy is 0.818\n",
      "roc-auc is 0.831\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "ann2 = Sequential([\n",
    "    Dense(25, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(12, activation=\"relu\"),\n",
    "    Dense(6),  # Remove activation from this Dense layer\n",
    "    LeakyReLU(alpha=0.3),  # Add a separate LeakyReLU layer after the Dense layer\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "                ])\n",
    "ann2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"]) #\n",
    "history = ann2.fit(X_train2_scaled, y_train2, validation_data=(X_val_scaled ,y_val), epochs=1500)\n",
    "y_preds    = ann2.predict(X_test_scaled)\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_preds_binary)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_preds )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the available keys in the history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Create a plot with train and validation loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history[\"loss\"], 'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(history.history[\"val_loss\"], 'b', marker='.', label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation and Training loss keep decreasing until around 1000-1200 epochs were the validation loss starts increasing. That means the model starts to overfit the data. To mitigate overfitting we can consider **EarlyStopping**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "\n",
    " I expiremented with adding more layers to the architecture to increase complexity but it looks like there is no benefit by just adding layers. The dataset is small and increasing the number of parameters does not help. \n",
    " \n",
    " The fact that the model performs similarly with 1 hidden layer with 25 units and with 3 hidden layers with 25, 12, and 6 units suggests that the simpler architecture is sufficient to capture the underlying patterns in your dataset. \n",
    " \n",
    " Different activation functions, optimizations and epochs were considered did not see much improvement in the performance if any at all."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sub> This is a projet I did for the IBM DeepLearning and Reinforcement Learning course </sub>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera747-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
